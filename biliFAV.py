"""
Bilibiliæ”¶è—å¤¹è§†é¢‘ä¸‹è½½å™¨
åŠŸèƒ½ï¼šç™»å½•Bç«™è´¦å·ï¼Œè·å–æ”¶è—å¤¹åˆ—è¡¨ï¼Œä¸‹è½½æ”¶è—å¤¹ä¸­çš„è§†é¢‘ï¼Œæ”¯æŒå¤šæ¸…æ™°åº¦é€‰æ‹©å’Œåå°åˆå¹¶
ä½œè€…ï¼šä¾è½¨æ³ QTY
"""

import asyncio
import toml
import qrcode
import sqlite3
import time
import random
import json
import os
import signal
import sys
import io
import threading
from pathlib import Path
from typing import Optional, Dict, List, Tuple, Any, Callable
import httpx
import concurrent.futures
import re
import logging
from datetime import datetime, timedelta
from tqdm import tqdm  # è¿›åº¦æ¡æ˜¾ç¤º
import ffmpeg
import shutil
import subprocess

# ========================
# ç³»ç»Ÿè®¾ç½®ä¸åˆå§‹åŒ–
# ========================

# è®¾ç½®ç³»ç»Ÿé»˜è®¤ç¼–ç ä¸ºUTF-8ï¼Œç¡®ä¿ä¸­æ–‡æ˜¾ç¤ºæ­£å¸¸
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# é…ç½®æ—¥å¿—ç³»ç»Ÿ
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# å‡å°‘HTTPXåº“çš„æ—¥å¿—è¾“å‡ºçº§åˆ«
httpx_logger = logging.getLogger("httpx")
httpx_logger.setLevel(logging.WARNING)

# æ§åˆ¶å°æ—¥å¿—å¤„ç†å™¨é…ç½®
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.WARNING)
console_formatter = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")
console_handler.setFormatter(console_formatter)

logger.addHandler(console_handler)
logger.propagate = False  # é˜²æ­¢æ—¥å¿—ä¼ é€’ç»™çˆ¶è®°å½•å™¨

# ========================
# å…¨å±€å¸¸é‡å®šä¹‰
# ========================

# é…ç½®æ–‡ä»¶è·¯å¾„
TOKEN_FILE = "bili_token.toml"  # ä¿å­˜ç™»å½•tokençš„æ–‡ä»¶
DB_FILE = ".get_my_favourite.sqlite"  # SQLiteæ•°æ®åº“æ–‡ä»¶

# HTTPè¯·æ±‚å¤´é…ç½®
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Referer": "https://www.bilibili.com"  # å¿…è¦çš„Refererå¤´
}

# æ¸…æ™°åº¦æ˜ å°„è¡¨ (æ¸…æ™°åº¦æè¿° -> ä»£ç )
QUALITY_MAP = {
    "4K": 120,
    "1080P60": 112,
    "1080P+": 116,
    "1080P": 80,
    "720P60": 74,
    "720P": 64,
    "480P": 32,
    "360P": 16,
    "æœ€ä½": 6  # æœ€ä½æ¸…æ™°åº¦
}

# æ¸…æ™°åº¦ä»£ç åˆ°æè¿°çš„æ˜ å°„ (ä»£ç  -> æ¸…æ™°åº¦æè¿°)
QUALITY_CODE_TO_DESC = {
    120: "4K",
    112: "1080P60",
    116: "1080P+",
    80: "1080P",
    74: "720P60",
    64: "720P",
    32: "480P",
    16: "360P",
    6: "æœ€ä½"
}

# éå¤§ä¼šå‘˜è´¦å·å¯ä¸‹è½½çš„æœ€é«˜æ¸…æ™°åº¦ä»£ç 
NON_MEMBER_MAX_QUALITY = 80 # 1080P

# ========================
# å…¨å±€çŠ¶æ€å˜é‡
# ========================

interrupted = False  # ç¨‹åºä¸­æ–­æ ‡å¿—
overwrite_all = False  # è¦†ç›–æ‰€æœ‰æ–‡ä»¶æ ‡å¿—
skip_existing = False  # è·³è¿‡æ‰€æœ‰å·²å­˜åœ¨æ–‡ä»¶æ ‡å¿—

# ========================
# è¾…åŠ©å‡½æ•°
# ========================

def signal_handler(sig, frame):
    """å¤„ç†ç³»ç»Ÿä¸­æ–­ä¿¡å·(Ctrl+C)"""
    global interrupted
    interrupted = True
    logger.warning("æ£€æµ‹åˆ°ä¸­æ–­ï¼Œæ­£åœ¨é€€å‡º...")
    print("\nç¨‹åºè¢«ä¸­æ–­ï¼Œæ­£åœ¨æ¸…ç†èµ„æº...")

# æ³¨å†Œä¿¡å·å¤„ç†å‡½æ•°
signal.signal(signal.SIGINT, signal_handler)

def sanitize_filename(filename: str) -> str:
    """
    æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦ï¼Œä½†ä¿ç•™emoji
    å‚æ•°:
        filename: åŸå§‹æ–‡ä»¶å
    è¿”å›:
        æ¸…ç†åçš„å®‰å…¨æ–‡ä»¶å
    """
    # ç§»é™¤Windowsæ–‡ä»¶ç³»ç»Ÿä¸å…è®¸çš„å­—ç¬¦: <>:"/\\|?*
    return re.sub(r'[<>:"/\\|?*]', '', filename)

def shorten_filename(filename: str, max_length: int = 180) -> str:
    """
    ç¼©çŸ­æ–‡ä»¶åä»¥é˜²æ­¢è·¯å¾„è¿‡é•¿
    å‚æ•°:
        filename: åŸå§‹æ–‡ä»¶å
        max_length: æœ€å¤§å…è®¸é•¿åº¦(é»˜è®¤180)
    è¿”å›:
        ç¼©çŸ­åçš„æ–‡ä»¶å
    """
    if len(filename) <= max_length:
        return filename
    
    # åˆ†ç¦»æ–‡ä»¶åå’Œæ‰©å±•å
    name, ext = os.path.splitext(filename)
    # æˆªæ–­æ–‡ä»¶åä¸»ä½“éƒ¨åˆ†
    name = name[:max_length - len(ext) - 10]  # ä¿ç•™10å­—ç¬¦ç»™éšæœºåç¼€
    # ç”Ÿæˆ8ä½éšæœºåç¼€é˜²æ­¢å†²çª
    suffix = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz1234567890', k=8))
    return f"{name}_{suffix}{ext}"

# ========================
# ä¸»ä¸‹è½½å™¨ç±»
# ========================

class BiliFavDownloader:
    """Bilibiliæ”¶è—å¤¹è§†é¢‘ä¸‹è½½å™¨ä¸»ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–ä¸‹è½½å™¨å®ä¾‹"""
        self.cookies = {}  # å­˜å‚¨ç™»å½•cookies
        self.token_data = {}  # å­˜å‚¨ç™»å½•tokenæ•°æ®
        self.all_data = []  # å­˜å‚¨æ‰€æœ‰æ”¶è—å¤¹æ•°æ®
        self.db_exists = Path(DB_FILE).exists()  # æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        self.is_member = False  # ç”¨æˆ·æ˜¯å¦ä¸ºå¤§ä¼šå‘˜
        self.qr_file = None  # äºŒç»´ç ä¿å­˜è·¯å¾„(é»˜è®¤ä¸ä¿å­˜)
        self.ffmpeg_available = False  # FFmpegæ˜¯å¦å¯ç”¨
        self.ffmpeg_version = "æœªçŸ¥"  # FFmpegç‰ˆæœ¬ä¿¡æ¯
        self.ffmpeg_path = None  # FFmpegå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„
        self.merge_queue = []  # éŸ³è§†é¢‘åˆå¹¶ä»»åŠ¡é˜Ÿåˆ—
        self.merge_lock = threading.Lock()  # åˆå¹¶é˜Ÿåˆ—çš„çº¿ç¨‹é”
        self.merge_thread = None  # åˆå¹¶çº¿ç¨‹å¯¹è±¡
        self.merge_running = True  # åˆå¹¶çº¿ç¨‹è¿è¡Œæ ‡å¿—
        self.last_updated = None  # æ•°æ®åº“æœ€åæ›´æ–°æ—¶é—´
        self.current_update_time = None  # å½“å‰æ›´æ–°æ—¶é—´
        self.first_run = not self.db_exists  # æ˜¯å¦é¦–æ¬¡è¿è¡Œæ ‡å¿—
    
    async def initialize(self) -> bool:
        """
        åˆå§‹åŒ–ä¸‹è½½å™¨
        æ­¥éª¤:
          1. æ£€æŸ¥FFmpegå¯ç”¨æ€§
          2. æ£€æŸ¥å¹¶åŠ è½½token
          3. äºŒç»´ç ç™»å½•(å¦‚æœéœ€è¦)
          4. æ£€æŸ¥ä¼šå‘˜çŠ¶æ€
          5. å¯åŠ¨åˆå¹¶çº¿ç¨‹
          6. è·å–æ•°æ®åº“æœ€åæ›´æ–°æ—¶é—´
        è¿”å›:
            bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
        """
        global interrupted
        
        # 1. æ£€æŸ¥FFmpegæ˜¯å¦å¯ç”¨
        self.check_ffmpeg()
        
        # 2. æ£€æŸ¥å¹¶åŠ è½½token
        self.token_data = await self.check_token()
        if not self.token_data:
            print("æœªæ£€æµ‹åˆ°ç™»å½•ä¿¡æ¯ï¼Œéœ€è¦ç™»å½•...")
            # 3. äºŒç»´ç ç™»å½•
            self.token_data = await self.qr_login()
            if interrupted:  # æ£€æŸ¥æ˜¯å¦åœ¨ç™»å½•è¿‡ç¨‹ä¸­è¢«ä¸­æ–­
                print("ç™»å½•è¿‡ç¨‹è¢«ä¸­æ–­")
                return False
            if self.token_data:
                self.save_token(self.token_data)
            else:
                print("ç™»å½•å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
                return False
        
        # è®¾ç½®cookies
        if self.token_data:
            self.cookies = self.token_data["cookies"]
        
        # 4. æ£€æŸ¥ä¼šå‘˜çŠ¶æ€
        if self.cookies:
            try:
                if interrupted:  # å†æ¬¡æ£€æŸ¥ä¸­æ–­
                    return False
                print("æ­£åœ¨æ£€æŸ¥ä¼šå‘˜çŠ¶æ€...")
                self.is_member = await self.check_member_status()
                if self.is_member:
                    print("æ£€æµ‹åˆ°å¤§ä¼šå‘˜è´¦å·ï¼Œå¯ä¸‹è½½é«˜åˆ†è¾¨ç‡è§†é¢‘")
                else:
                    print("æ™®é€šè´¦å·ï¼Œæœ€é«˜å¯ä¸‹è½½1080Påˆ†è¾¨ç‡")
            except Exception as e:
                print(f"æ£€æŸ¥ä¼šå‘˜çŠ¶æ€å¤±è´¥: {str(e)}")
                print("é»˜è®¤ä½¿ç”¨æ™®é€šè´¦å·æ¨¡å¼")
                self.is_member = False
        
        # 5. å¯åŠ¨åˆå¹¶çº¿ç¨‹
        self.start_merge_thread()
        
        # 6. è·å–æ•°æ®åº“æœ€åæ›´æ–°æ—¶é—´
        self.get_last_updated_time()
        
        return True
    
    def get_last_updated_time(self):
        """ä»æ•°æ®åº“è·å–æœ€åæ›´æ–°æ—¶é—´"""
        if not self.db_exists:
            self.last_updated = None
            return
        
        try:
            conn = sqlite3.connect(DB_FILE)
            c = conn.cursor()
            
            # æ£€æŸ¥è¡¨ç»“æ„æ˜¯å¦åŒ…å«last_updatedå­—æ®µ
            c.execute("PRAGMA table_info(favorites)")
            columns = [col[1] for col in c.fetchall()]
            if "last_updated" not in columns:
                self.last_updated = None
                return
            
            # æŸ¥è¯¢æœ€åæ›´æ–°æ—¶é—´
            c.execute("SELECT MAX(last_updated) FROM favorites")
            result = c.fetchone()
            if result and result[0]:
                self.last_updated = datetime.fromisoformat(result[0])
            else:
                self.last_updated = None
        except Exception as e:
            print(f"è·å–æ•°æ®åº“æœ€åæ›´æ–°æ—¶é—´å¤±è´¥: {str(e)}")
            self.last_updated = None
        finally:
            if conn:
                conn.close()
    
    def check_ffmpeg(self):
        """
        æ£€æŸ¥ç³»ç»Ÿä¸Šæ˜¯å¦å®‰è£…äº†FFmpegï¼Œæ”¯æŒè·¨å¹³å°æ£€æµ‹
        æŒ‰ç…§æµç¨‹å›¾é€»è¾‘ï¼š
        1. æ£€æµ‹æ“ä½œç³»ç»Ÿç±»å‹
        2. Windows: ä½¿ç”¨shutil.whichè¿›è¡Œå…¨å±€æ£€æµ‹
        3. Unix-like (Linux/macOS): ä½¿ç”¨whichå‘½ä»¤è¿›è¡Œå…¨å±€æ£€æµ‹
        4. å¦‚æœå…¨å±€æ£€æµ‹å¤±è´¥ï¼Œè¿›è¡Œä¸‰å±‚å‘ä¸‹æœç´¢ï¼ˆç¨‹åºç›®å½•ã€ç¬¬ä¸€å±‚å­ç›®å½•ã€ç¬¬äºŒå±‚å­ç›®å½•ï¼‰
        5. å¯¹æ‰¾åˆ°çš„è·¯å¾„è¿›è¡Œæœ‰æ•ˆæ€§æµ‹è¯•
        6. å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œå°è¯•ç›´æ¥è¿è¡Œffmpegå‘½ä»¤
        """
        import platform
        
        # è·å–æ“ä½œç³»ç»Ÿä¿¡æ¯
        system = platform.system().lower()
        is_windows = system == "windows"
        is_linux = system == "linux"
        is_macos = system == "darwin"
        
        print(f"æ£€æµ‹åˆ°æ“ä½œç³»ç»Ÿ: {platform.system()} ({platform.release()})")
        
        # 1. å…¨å±€æ£€æµ‹ï¼ˆæ ¹æ®æ“ä½œç³»ç»Ÿç±»å‹ä½¿ç”¨ä¸åŒæ–¹æ³•ï¼‰
        global_ffmpeg_path = None
        
        if is_windows:
            # Windows: ä½¿ç”¨shutil.whichè¿›è¡Œå…¨å±€æ£€æµ‹
            global_ffmpeg_path = shutil.which("ffmpeg")
            if global_ffmpeg_path:
                print(f"Windowså…¨å±€æ£€æµ‹: æ‰¾åˆ°FFmpegè·¯å¾„ - {global_ffmpeg_path}")
        else:
            # Unix-like (Linux/macOS): ä½¿ç”¨whichå‘½ä»¤è¿›è¡Œå…¨å±€æ£€æµ‹
            try:
                result = subprocess.run(
                    ["which", "ffmpeg"],
                    capture_output=True,
                    text=True,
                    encoding='utf-8',
                    errors='ignore'
                )
                if result.returncode == 0:
                    global_ffmpeg_path = result.stdout.strip()
                    print(f"Unixå…¨å±€æ£€æµ‹: æ‰¾åˆ°FFmpegè·¯å¾„ - {global_ffmpeg_path}")
            except Exception as e:
                print(f"Unixå…¨å±€æ£€æµ‹å¤±è´¥: {str(e)}")
        
        # æµ‹è¯•å…¨å±€æ£€æµ‹åˆ°çš„FFmpegè·¯å¾„
        if global_ffmpeg_path and self._test_ffmpeg_path(global_ffmpeg_path):
            self.ffmpeg_path = global_ffmpeg_path
            self.ffmpeg_available = True
            print(f"FFmpegæ£€æµ‹æˆåŠŸ (å…¨å±€è·¯å¾„: {self.ffmpeg_path}, ç‰ˆæœ¬: {self.ffmpeg_version})")
            return
        
        # 2. å…¨å±€æ£€æµ‹å¤±è´¥ï¼Œè¿›è¡Œä¸‰å±‚å‘ä¸‹æœç´¢
        print("å…¨å±€æ£€æµ‹å¤±è´¥ï¼Œå¼€å§‹æœ¬åœ°æœç´¢...")
        program_dir = os.path.dirname(os.path.abspath(__file__))
        
        # æœç´¢ç­–ç•¥ï¼šç¨‹åºç›®å½• -> ç¬¬ä¸€å±‚å­ç›®å½• -> ç¬¬äºŒå±‚å­ç›®å½•
        search_depths = [0, 1, 2]  # 0=ä»…ç¨‹åºç›®å½•ï¼Œ1=ç¨‹åºç›®å½•+ç¬¬ä¸€å±‚å­ç›®å½•ï¼Œ2=ç¨‹åºç›®å½•+ç¬¬ä¸€å±‚+ç¬¬äºŒå±‚å­ç›®å½•
        
        for depth in search_depths:
            print(f"æ­£åœ¨æœç´¢ç¬¬{depth+1}å±‚ç›®å½•...")
            local_ffmpeg_path = self._find_ffmpeg_in_directory(program_dir, max_depth=depth)
            
            if local_ffmpeg_path and self._test_ffmpeg_path(local_ffmpeg_path):
                self.ffmpeg_path = local_ffmpeg_path
                self.ffmpeg_available = True
                print(f"FFmpegæ£€æµ‹æˆåŠŸ (æœ¬åœ°æœç´¢æ·±åº¦{depth}: {self.ffmpeg_path}, ç‰ˆæœ¬: {self.ffmpeg_version})")
                return
        
        # 3. å¦‚æœä¸Šè¿°æ–¹æ³•éƒ½å¤±è´¥ï¼Œå°è¯•ç›´æ¥è¿è¡Œffmpegå‘½ä»¤
        print("æœ¬åœ°æœç´¢å¤±è´¥ï¼Œå°è¯•ç›´æ¥è¿è¡Œffmpegå‘½ä»¤...")
        try:
            # æ ¹æ®æ“ä½œç³»ç»Ÿä½¿ç”¨ä¸åŒçš„å‘½ä»¤
            if is_windows:
                result = subprocess.run(
                    ["ffmpeg", "-version"],
                    capture_output=True,
                    text=True,
                    encoding='utf-8',
                    errors='ignore',
                    creationflags=subprocess.CREATE_NO_WINDOW
                )
            else:
                result = subprocess.run(
                    ["ffmpeg", "-version"],
                    capture_output=True,
                    text=True,
                    encoding='utf-8',
                    errors='ignore'
                )
            
            if result.returncode == 0:
                self.ffmpeg_available = True
                self.ffmpeg_path = "ffmpeg"  # ä½¿ç”¨å‘½ä»¤åç§°
                self._parse_ffmpeg_version(result.stdout)
                print(f"FFmpegæ£€æµ‹æˆåŠŸ (å‘½ä»¤æ–¹å¼, ç‰ˆæœ¬: {self.ffmpeg_version})")
                return
        except Exception as e:
            print(f"ç›´æ¥è¿è¡Œffmpegå‘½ä»¤å¤±è´¥: {str(e)}")
        
        # 4. æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥
        print("è­¦å‘Š: æœªæ£€æµ‹åˆ°FFmpegï¼ŒDASHæ ¼å¼è§†é¢‘å°†æ— æ³•åˆå¹¶éŸ³é¢‘")
        print("   è¯·å®‰è£…FFmpegå¹¶æ·»åŠ åˆ°ç³»ç»ŸPATHï¼Œæˆ–æ”¾ç½®åœ¨ç¨‹åºç›®å½•ä¸‹")
        print("   ä¸‹è½½åœ°å€ï¼šhttps://ffmpeg.org/download.html")
        self.ffmpeg_available = False
    
    def _find_ffmpeg_in_directory(self, directory: str, max_depth: int = 2) -> Optional[str]:
        """
        åœ¨æŒ‡å®šç›®å½•ä¸­æœç´¢FFmpegå¯æ‰§è¡Œæ–‡ä»¶ï¼Œæ”¯æŒå¤šå±‚å‘ä¸‹æœç´¢
        å‚æ•°:
            directory: èµ·å§‹æœç´¢ç›®å½•
            max_depth: æœ€å¤§æœç´¢æ·±åº¦ï¼ˆ0=ä»…å½“å‰ç›®å½•ï¼Œ1=å½“å‰ç›®å½•+ç¬¬ä¸€å±‚å­ç›®å½•ï¼Œ2=å½“å‰ç›®å½•+ç¬¬ä¸€å±‚+ç¬¬äºŒå±‚å­ç›®å½•ï¼‰
        è¿”å›:
            FFmpegå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
        """
        ffmpeg_names = ["ffmpeg", "ffmpeg.exe", "ffmpeg.bat"]
        
        # æœç´¢å½“å‰ç›®å½•
        for file in os.listdir(directory):
            file_path = os.path.join(directory, file)
            if os.path.isfile(file_path) and file.lower() in ffmpeg_names:
                return file_path
        
        # å¦‚æœå…è®¸æ·±åº¦æœç´¢ï¼Œæœç´¢å­ç›®å½•
        if max_depth > 0:
            for item in os.listdir(directory):
                item_path = os.path.join(directory, item)
                if os.path.isdir(item_path):
                    # æœç´¢ç¬¬ä¸€å±‚å­ç›®å½•
                    for sub_file in os.listdir(item_path):
                        sub_file_path = os.path.join(item_path, sub_file)
                        if os.path.isfile(sub_file_path) and sub_file.lower() in ffmpeg_names:
                            return sub_file_path
                    
                    # å¦‚æœå…è®¸ç¬¬äºŒå±‚æ·±åº¦æœç´¢ï¼Œæœç´¢ç¬¬äºŒå±‚å­ç›®å½•
                    if max_depth > 1:
                        for sub_item in os.listdir(item_path):
                            sub_item_path = os.path.join(item_path, sub_item)
                            if os.path.isdir(sub_item_path):
                                for sub_sub_file in os.listdir(sub_item_path):
                                    sub_sub_file_path = os.path.join(sub_item_path, sub_sub_file)
                                    if os.path.isfile(sub_sub_file_path) and sub_sub_file.lower() in ffmpeg_names:
                                        return sub_sub_file_path
        
        return None
    
    def _test_ffmpeg_path(self, ffmpeg_path: str) -> bool:
        """æµ‹è¯•FFmpegè·¯å¾„æ˜¯å¦æœ‰æ•ˆ"""
        try:
            result = subprocess.run(
                [ffmpeg_path, "-version"],
                capture_output=True,
                text=True,
                encoding='utf-8',
                errors='ignore',
                creationflags=subprocess.CREATE_NO_WINDOW
            )
            if result.returncode == 0:
                self._parse_ffmpeg_version(result.stdout)
                return True
        except Exception:
            pass
        return False
    
    def _parse_ffmpeg_version(self, version_output: str):
        """è§£æFFmpegç‰ˆæœ¬ä¿¡æ¯"""
        try:
            version_line = version_output.split('\n')[0]
            parts = version_line.split(' ')
            self.ffmpeg_version = parts[2] if len(parts) > 2 else "æœªçŸ¥"
        except Exception:
            self.ffmpeg_version = "æœªçŸ¥"
    
    def start_merge_thread(self):
        """å¯åŠ¨åå°åˆå¹¶çº¿ç¨‹"""
        if not self.ffmpeg_available:
            print("åˆå¹¶çº¿ç¨‹æœªå¯åŠ¨ï¼Œå› ä¸ºFFmpegä¸å¯ç”¨")
            return
        
        self.merge_running = True
        # åˆ›å»ºå®ˆæŠ¤çº¿ç¨‹ï¼Œä¸»çº¿ç¨‹é€€å‡ºæ—¶è‡ªåŠ¨ç»“æŸ
        self.merge_thread = threading.Thread(target=self._merge_worker, daemon=True)
        self.merge_thread.start()
        print("åå°åˆå¹¶çº¿ç¨‹å·²å¯åŠ¨")
    
    def stop_merge_thread(self):
        """åœæ­¢åå°åˆå¹¶çº¿ç¨‹"""
        if self.merge_thread and self.merge_thread.is_alive():
            self.merge_running = False
            self.merge_thread.join(timeout=5.0)  # ç­‰å¾…çº¿ç¨‹ç»“æŸ
            print("åå°åˆå¹¶çº¿ç¨‹å·²åœæ­¢")
    
    def _merge_worker(self):
        """åˆå¹¶å·¥ä½œçº¿ç¨‹çš„ä¸»å‡½æ•°"""
        print(f"\nåˆå¹¶çº¿ç¨‹å¯åŠ¨ (FFmpegè·¯å¾„: {self.ffmpeg_path})")
        
        # æŒç»­è¿è¡Œç›´åˆ°æ”¶åˆ°åœæ­¢ä¿¡å·ä¸”é˜Ÿåˆ—ä¸ºç©º
        while self.merge_running or self.merge_queue:
            if interrupted:  # æ£€æŸ¥å…¨å±€ä¸­æ–­æ ‡å¿—
                break
                
            if not self.merge_queue:
                time.sleep(0.5)  # é˜Ÿåˆ—ä¸ºç©ºæ—¶çŸ­æš‚ä¼‘çœ 
                continue
            
            # ä»é˜Ÿåˆ—ä¸­è·å–ä»»åŠ¡
            with self.merge_lock:
                task = self.merge_queue.pop(0) if self.merge_queue else None
            
            if not task:
                continue
                
            # è§£åŒ…ä»»åŠ¡å‚æ•°
            video_file, audio_file, output_file, title, bvid = task
            
            try:
                print(f"\nå¼€å§‹åˆå¹¶: {title} ({bvid}) [ä½¿ç”¨FFmpeg]")
                
                # æ„å»ºFFmpegå‘½ä»¤
                ffmpeg_cmd = [
                    self.ffmpeg_path,
                    '-i', video_file,  # è¾“å…¥è§†é¢‘æ–‡ä»¶
                    '-i', audio_file,  # è¾“å…¥éŸ³é¢‘æ–‡ä»¶
                    '-c', 'copy',      # æµå¤åˆ¶æ¨¡å¼(ä¸é‡æ–°ç¼–ç )
                    '-map', '0:v:0',   # é€‰æ‹©ç¬¬ä¸€ä¸ªè¾“å…¥çš„è§†é¢‘æµ
                    '-map', '1:a:0',   # é€‰æ‹©ç¬¬äºŒä¸ªè¾“å…¥çš„éŸ³é¢‘æµ
                    '-y',               # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                    output_file        # è¾“å‡ºæ–‡ä»¶
                ]
                
                # æ‰§è¡ŒFFmpegå‘½ä»¤
                process = subprocess.run(
                    ffmpeg_cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    encoding='utf-8',
                    errors='ignore',
                    creationflags=subprocess.CREATE_NO_WINDOW
                )
                
                # æ£€æŸ¥å‘½ä»¤æ‰§è¡Œç»“æœ
                if process.returncode != 0:
                    error_msg = process.stderr if process.stderr else "æ— é”™è¯¯ä¿¡æ¯"
                    raise Exception(f"FFmpegåˆå¹¶å¤±è´¥ (è¿”å›ç  {process.returncode}): {error_msg}")
                
                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(video_file):
                    os.remove(video_file)
                if os.path.exists(audio_file):
                    os.remove(audio_file)
                
                print(f"åˆå¹¶å®Œæˆ: {title} ({bvid})\n")
                
            except Exception as e:
                print(f"åˆå¹¶è§†é¢‘å¤±è´¥: {title} ({bvid}) - {str(e)}")
                # åˆå¹¶å¤±è´¥æ—¶å°è¯•ä¿å­˜è§†é¢‘æ–‡ä»¶
                if os.path.exists(video_file):
                    try:
                        os.rename(video_file, output_file)
                        print(f"å·²ä¿å­˜è§†é¢‘æ–‡ä»¶ï¼ˆæ— éŸ³é¢‘ï¼‰: {title}")
                    except Exception:
                        pass
    
    def queue_merge_task(self, video_file: str, audio_file: str, output_file: str, title: str, bvid: str) -> bool:
        """
        å°†åˆå¹¶ä»»åŠ¡æ·»åŠ åˆ°é˜Ÿåˆ—
        å‚æ•°:
            video_file: è§†é¢‘ä¸´æ—¶æ–‡ä»¶è·¯å¾„
            audio_file: éŸ³é¢‘ä¸´æ—¶æ–‡ä»¶è·¯å¾„
            output_file: æœ€ç»ˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
            title: è§†é¢‘æ ‡é¢˜
            bvid: è§†é¢‘BVå·
        è¿”å›:
            bool: æ˜¯å¦æˆåŠŸåŠ å…¥é˜Ÿåˆ—
        """
        if not self.ffmpeg_available:
            print(f"æ— æ³•åˆå¹¶: {title} ({bvid}) - FFmpegä¸å¯ç”¨")
            return False
        
        # ä½¿ç”¨çº¿ç¨‹é”ä¿è¯é˜Ÿåˆ—æ“ä½œå®‰å…¨
        with self.merge_lock:
            self.merge_queue.append((video_file, audio_file, output_file, title, bvid))
        
        print(f"\nå·²åŠ å…¥åˆå¹¶é˜Ÿåˆ—: {title} (é˜Ÿåˆ—é•¿åº¦: {len(self.merge_queue)})")
        return True
    
    def save_token(self, token_data: Dict):
        """ä¿å­˜tokenåˆ°TOMLæ–‡ä»¶"""
        try:
            with open(TOKEN_FILE, "w") as f:
                toml.dump(token_data, f)
            print(f"ç™»å½•ä¿¡æ¯å·²ä¿å­˜\n")
        except Exception as e:
            print(f"ä¿å­˜ç™»å½•ä¿¡æ¯å¤±è´¥: {str(e)}")
    
    async def check_member_status(self) -> bool:
        """æ£€æŸ¥ç”¨æˆ·å¤§ä¼šå‘˜çŠ¶æ€ï¼Œæ”¯æŒè‡ªåŠ¨é‡æ–°ç™»å½•"""
        try:
            async with httpx.AsyncClient(headers=HEADERS, cookies=self.cookies, timeout=10.0) as client:
                # è°ƒç”¨APIè·å–ç”¨æˆ·ä¿¡æ¯
                resp = await client.get("https://api.bilibili.com/x/web-interface/nav")
                resp.raise_for_status()
                data = resp.json()
                
                # æ£€æŸ¥ç™»å½•çŠ¶æ€
                if data.get("code") == -101:
                    print("æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆï¼Œå°è¯•é‡æ–°ç™»å½•...")
                    new_token = await self.qr_login()
                    if new_token:
                        self.cookies = new_token["cookies"]
                        self.token_data = new_token
                        self.save_token(new_token)
                        print("é‡æ–°ç™»å½•æˆåŠŸï¼Œé‡è¯•ä¼šå‘˜çŠ¶æ€æ£€æµ‹...")
                        # é‡è¯•ä¸€æ¬¡
                        return await self.check_member_status()
                    else:
                        print("é‡æ–°ç™»å½•å¤±è´¥ï¼Œä½¿ç”¨æ™®é€šè´¦å·æ¨¡å¼")
                        return False
                
                if data.get("code") == 0:
                    return data["data"].get("vipStatus", 0) == 1
                else:
                    print(f"ä¼šå‘˜çŠ¶æ€APIé”™è¯¯: {data.get('message')}")
                    return False
        except Exception as e:
            print(f"æ£€æŸ¥ä¼šå‘˜çŠ¶æ€å¤±è´¥: {str(e)}")
            return False

    def get_token(self) -> Dict:
        """è·å–å½“å‰tokenæ•°æ®"""
        return self.token_data
    
    async def check_token(self) -> Optional[Dict]:
        """æ£€æŸ¥å¹¶åŠ è½½tokenæ–‡ä»¶"""
        if Path(TOKEN_FILE).exists():
            try:
                return toml.load(TOKEN_FILE)
            except Exception as e:
                print(f"è¯»å–ç™»å½•ä¿¡æ¯å¤±è´¥: {str(e)}")
                # åˆ é™¤æ— æ•ˆçš„tokenæ–‡ä»¶
                try:
                    os.remove(TOKEN_FILE)
                    print("å·²åˆ é™¤æ— æ•ˆçš„ç™»å½•ä¿¡æ¯")
                except:
                    pass
        return None

    async def qr_login(self, qr_output: str = None) -> Optional[Dict]:
        """
        äºŒç»´ç ç™»å½•æµç¨‹
        å‚æ•°:
            qr_output: äºŒç»´ç å›¾ç‰‡ä¿å­˜è·¯å¾„(å¯é€‰)
        è¿”å›:
            Dict: ç™»å½•æˆåŠŸåçš„tokenæ•°æ®
        """
        print("è¯·æ‰“å¼€å“”å“©å“”å“©APPæ‰«æäºŒç»´ç ç™»å½•...")
        
        # è®¾ç½®äºŒç»´ç è¾“å‡ºè·¯å¾„
        if qr_output:
            self.qr_file = qr_output
            print(f"äºŒç»´ç å°†ä¿å­˜åˆ°: {qr_output}")
        else:
            self.qr_file = None
        
        try:
            async with httpx.AsyncClient(headers=HEADERS, timeout=30.0) as client:
                # 1. è·å–äºŒç»´ç ä¿¡æ¯
                qr_resp = await client.get("https://passport.bilibili.com/x/passport-login/web/qrcode/generate")
                qr_resp.raise_for_status()
                qr_data = qr_resp.json()
                
                if qr_data.get("code") != 0:
                    print(f"è·å–äºŒç»´ç å¤±è´¥: {qr_data.get('message')}")
                    return None
                
                qr_url = qr_data["data"]["url"]
                qrcode_key = qr_data["data"]["qrcode_key"]
                
                # 2. åˆ›å»ºäºŒç»´ç 
                qr = qrcode.QRCode(
                    version=1,
                    error_correction=qrcode.constants.ERROR_CORRECT_L,
                    box_size=15,  # å¢å¤§box_sizeä»¥æé«˜åˆ†è¾¨ç‡
                    border=2,
                )
                qr.add_data(qr_url)
                qr.make(fit=True)
                
                # 3. åœ¨ç»ˆç«¯æ‰“å°äºŒç»´ç 
                print("\nç»ˆç«¯äºŒç»´ç é¢„è§ˆ:")
                qr.print_ascii(invert=True)  # ä½¿ç”¨ASCIIå­—ç¬¦æ‰“å°äºŒç»´ç 
                
                # 4. ä¿å­˜äºŒç»´ç å›¾ç‰‡(å¦‚æœéœ€è¦)
                if self.qr_file:
                    img = qr.make_image(fill_color="black", back_color="white")
                    img = img.resize((600, 600))  # è°ƒæ•´å›¾åƒå¤§å°
                    img.save(self.qr_file)
                    print(f"\näºŒç»´ç å·²ä¿å­˜ä¸º: {self.qr_file}")
                
                print("\nè¯·ä½¿ç”¨å“”å“©å“”å“©APPæ‰«ç ç™»å½•ï¼ˆäºŒç»´ç æœ‰æ•ˆæœŸä¸º180ç§’ï¼‰")
                print("æŒ‰Ctrl+Cå¯å–æ¶ˆç™»å½•")
                
                # 5. è½®è¯¢ç™»å½•çŠ¶æ€
                for i in range(180):  # 180ç§’è¶…æ—¶
                    if interrupted:
                        print("\nç™»å½•è¿‡ç¨‹è¢«ä¸­æ–­")
                        return None
                    
                    print(f"\rç­‰å¾…æ‰«ç ç¡®è®¤... [{i}/180ç§’]", end="", flush=True)
                    
                    try:
                        # æ£€æŸ¥ç™»å½•çŠ¶æ€
                        check_resp = await client.get(
                            "https://passport.bilibili.com/x/passport-login/web/qrcode/poll",
                            params={"qrcode_key": qrcode_key},
                            timeout=5.0
                        )
                        check_resp.raise_for_status()
                        check_data = check_resp.json()
                    except httpx.TimeoutException:
                        # è¶…æ—¶ç»§ç»­å°è¯•
                        await asyncio.sleep(1)
                        continue
                    except Exception as e:
                        print(f"\næ£€æŸ¥ç™»å½•çŠ¶æ€å¤±è´¥: {str(e)}")
                        await asyncio.sleep(1)
                        continue
                    
                    # å¤„ç†ä¸åŒçŠ¶æ€ç 
                    if check_data.get("data", {}).get("code") == 86038:  # äºŒç»´ç è¿‡æœŸ
                        print("\näºŒç»´ç å·²è¿‡æœŸï¼Œè¯·é‡æ–°è¿è¡Œç¨‹åºè·å–æ–°äºŒç»´ç ")
                        return None
                    elif check_data.get("data", {}).get("code") == 86039:  # æœªæ‰«æ
                        await asyncio.sleep(1)
                        continue
                    elif check_data.get("data", {}).get("code") == 0:  # ç™»å½•æˆåŠŸ
                        # ä»å“åº”å¤´è§£æcookies
                        cookies = self.parse_cookies(str(check_resp.headers.get("set-cookie", "")))
                        if not cookies:
                            print("\nè·å–ç™»å½•Cookieå¤±è´¥")
                            return None
                        
                        # æ„å»ºtokenä¿¡æ¯
                        token_info = {
                            "cookies": cookies,
                            "timestamp": int(time.time())
                        }
                        print("\nç™»å½•æˆåŠŸï¼")
                        return token_info
                    
                    # ç­‰å¾…1ç§’åç»§ç»­
                    await asyncio.sleep(1)
                
                print("\nç™»å½•è¶…æ—¶ï¼Œè¯·é‡è¯•")
                return None
        except Exception as e:
            print(f"\nç™»å½•å‡ºé”™: {str(e)}")
            return None
    
    def parse_cookies(self, cookie_header: str) -> Dict:
        """
        ä»HTTPå“åº”å¤´è§£æcookies
        å‚æ•°:
            cookie_header: Set-Cookieå¤´å†…å®¹
        è¿”å›:
            Dict: è§£æå‡ºçš„cookieså­—å…¸
        """
        cookies = {}
        if not cookie_header:
            return cookies
        
        # è§£æå…³é”®cookies
        for item in cookie_header.split(","):
            item = item.strip()
            if "SESSDATA=" in item:
                cookies["SESSDATA"] = item.split("SESSDATA=")[1].split(";")[0]
            elif "bili_jct=" in item:
                cookies["bili_jct"] = item.split("bili_jct=")[1].split(";")[0]
            elif "DedeUserID=" in item:
                cookies["DedeUserID"] = item.split("DedeUserID=")[1].split(";")[0]
        return cookies

    async def get_favorites(self, session: httpx.AsyncClient) -> List[Dict]:
        """è·å–ç”¨æˆ·åˆ›å»ºçš„æ”¶è—å¤¹åˆ—è¡¨ï¼Œæ”¯æŒè‡ªåŠ¨é‡æ–°ç™»å½•"""
        try:
            print("æ­£åœ¨è·å–æ”¶è—å¤¹åˆ—è¡¨...")
            
            # æ£€æŸ¥DedeUserIDæ˜¯å¦å­˜åœ¨
            dede_user_id = session.cookies.get("DedeUserID")
            if not dede_user_id:
                print("é”™è¯¯: æœªæ‰¾åˆ°DedeUserIDï¼Œè¯·é‡æ–°ç™»å½•")
                return []
            
            # å‘é€APIè¯·æ±‚
            resp = await session.get(
                "https://api.bilibili.com/x/v3/fav/folder/created/list-all",
                params={"up_mid": dede_user_id},
                timeout=30.0
            )
            resp.raise_for_status()
            data = resp.json()
            
            # æ£€æŸ¥ç™»å½•å¤±æ•ˆ
            if data.get("code") == -101:
                print("æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆï¼Œå°è¯•é‡æ–°ç™»å½•...")
                new_token = await self.qr_login()
                if new_token:
                    # æ›´æ–°sessionçš„cookies
                    session.cookies.update(new_token["cookies"])
                    self.cookies = new_token["cookies"]
                    self.token_data = new_token
                    self.save_token(new_token)
                    print("é‡æ–°ç™»å½•æˆåŠŸï¼Œé‡è¯•æ”¶è—å¤¹API...")
                    # é‡è¯•ä¸€æ¬¡
                    return await self.get_favorites(session)
                else:
                    print("é‡æ–°ç™»å½•å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨")
                    return []
            
            # æ£€æŸ¥APIå“åº”çŠ¶æ€ç 
            if data.get("code") != 0:
                error_msg = data.get('message', 'æœªçŸ¥é”™è¯¯')
                print(f"è·å–æ”¶è—å¤¹åˆ—è¡¨å¤±è´¥: {error_msg}")
                return []
            
            # æ£€æŸ¥dataå­—æ®µæ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºNone
            if data.get("data") is None:
                print("é”™è¯¯: APIå“åº”ä¸­dataå­—æ®µä¸ºNone")
                return []
            
            # æ£€æŸ¥listå­—æ®µæ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºNone
            favorite_list = data["data"].get("list")
            if favorite_list is None:
                print("é”™è¯¯: APIå“åº”ä¸­listå­—æ®µä¸ºNone")
                return []
            
            # è¿”å›æ”¶è—å¤¹åˆ—è¡¨
            return favorite_list
            
        except httpx.TimeoutException:
            print("è·å–æ”¶è—å¤¹åˆ—è¡¨è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
            return []
        except httpx.HTTPStatusError as e:
            print(f"HTTPé”™è¯¯: {e.response.status_code}")
            return []
        except Exception as e:
            print(f"è·å–æ”¶è—å¤¹åˆ—è¡¨å¤±è´¥: {str(e)}")
            return []
    
    async def get_favorite_detail(self, session: httpx.AsyncClient, media_id: int, media_count: int) -> List[Dict]:
        """è·å–æŒ‡å®šæ”¶è—å¤¹çš„è¯¦ç»†å†…å®¹"""
        global interrupted
        all_items = []
        page = 1
        page_size = 20  # æ¯é¡µé¡¹ç›®æ•°
        max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
        consecutive_failures = 0  # è¿ç»­å¤±è´¥æ¬¡æ•°
        
        try:
            print(f"å¼€å§‹è·å–æ”¶è—å¤¹å†…å®¹ï¼Œå…±çº¦{media_count}é¡¹...")
            
            # åˆ›å»ºè¿›åº¦æ¡
            pbar = tqdm(total=media_count, desc=f"æ”¶è—å¤¹ID {media_id}", unit="é¡¹")
            
            while not interrupted:
                # éšæœºå»¶è¿Ÿé˜²æ­¢è¯·æ±‚è¿‡å¿«
                delay = random.uniform(0.1, 0.8)
                await asyncio.sleep(delay)
                
                retry_count = 0
                page_success = False
                items = []
                
                # é‡è¯•æœºåˆ¶
                while retry_count < max_retries and not page_success and not interrupted:
                    try:
                        # è·å–å½“å‰é¡µå†…å®¹
                        resp = await session.get(
                            "https://api.bilibili.com/x/v3/fav/resource/list",
                            params={
                                "media_id": media_id,
                                "ps": page_size,
                                "pn": page,
                                "platform": "web"
                            },
                            timeout=30.0
                        )
                        resp.raise_for_status()
                        data = resp.json()
                        
                        if data.get("code") != 0:
                            error_msg = data.get('message', 'æœªçŸ¥é”™è¯¯')
                            if page == 1 and retry_count == 0:
                                print(f"è·å–æ”¶è—å¤¹è¯¦æƒ…å¤±è´¥: {error_msg}")
                            
                            # å¦‚æœæ˜¯ç™»å½•å¤±æ•ˆï¼Œå°è¯•é‡æ–°ç™»å½•
                            if data.get("code") == -101:
                                print("æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆï¼Œå°è¯•é‡æ–°ç™»å½•...")
                                new_token = await self.qr_login()
                                if new_token:
                                    # æ›´æ–°sessionçš„cookies
                                    session.cookies.update(new_token["cookies"])
                                    self.cookies = new_token["cookies"]
                                    self.token_data = new_token
                                    self.save_token(new_token)
                                    print("é‡æ–°ç™»å½•æˆåŠŸï¼Œé‡è¯•å½“å‰é¡µ...")
                                    # é‡è¯•å½“å‰é¡µ
                                    retry_count += 1
                                    continue
                            
                            # å…¶ä»–é”™è¯¯ï¼Œè®°å½•å¹¶é‡è¯•
                            retry_count += 1
                            if retry_count < max_retries:
                                print(f"ç¬¬{page}é¡µè·å–å¤±è´¥: {error_msg}, ç¬¬{retry_count}æ¬¡é‡è¯•...")
                                await asyncio.sleep(1.0)  # é‡è¯•å‰ç­‰å¾…
                                continue
                            else:
                                print(f"ç¬¬{page}é¡µè·å–å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {error_msg}")
                                break
                        
                        # æˆåŠŸè·å–æ•°æ®
                        page_success = True
                        consecutive_failures = 0  # é‡ç½®è¿ç»­å¤±è´¥è®¡æ•°
                        
                        # æå–é¡¹ç›®åˆ—è¡¨
                        items = data["data"].get("medias", [])
                        all_items.extend(items)
                        
                        # æ›´æ–°è¿›åº¦æ¡ï¼ˆå³ä½¿itemsä¸ºç©ºä¹Ÿæ›´æ–°0ï¼‰
                        pbar.update(len(items))
                        
                        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šé¡µ
                        has_more = data["data"].get("has_more", 0) == 1
                        
                        # å¦‚æœhas_more=0ï¼Œæ£€æŸ¥å®Œæˆåº¦
                        if not has_more:
                            current_count = len(all_items)
                            if current_count < media_count:
                                print(f"è­¦å‘Š: APIè¿”å›has_more=0ï¼Œä½†åªè·å–åˆ°{current_count}/{media_count}é¡¹")
                                # å¯ä»¥å°è¯•ç»§ç»­è·å–ä¸‹ä¸€é¡µï¼Œä½†è¿™é‡Œæˆ‘ä»¬å°Šé‡APIçš„æŒ‡ç¤º
                        
                        # åˆ¤æ–­æ˜¯å¦ç»§ç»­è·å–ä¸‹ä¸€é¡µ
                        if not has_more or len(items) < page_size:
                            # æ²¡æœ‰æ›´å¤šé¡µæˆ–å½“å‰é¡µä¸æ»¡ï¼Œç»“æŸå¾ªç¯
                            break
                        
                        # å‡†å¤‡è·å–ä¸‹ä¸€é¡µ
                        page += 1
                        if page > 50:  # å®‰å…¨é™åˆ¶
                            print("è¾¾åˆ°æœ€å¤§é¡µæ•°é™åˆ¶(50é¡µ)ï¼Œåœæ­¢è·å–")
                            break
                            
                    except httpx.TimeoutException:
                        retry_count += 1
                        if retry_count < max_retries:
                            print(f"ç¬¬{page}é¡µè¯·æ±‚è¶…æ—¶ï¼Œç¬¬{retry_count}æ¬¡é‡è¯•...")
                            await asyncio.sleep(2.0)  # è¶…æ—¶é‡è¯•ç­‰å¾…æ›´é•¿æ—¶é—´
                            continue
                        else:
                            print(f"ç¬¬{page}é¡µè¯·æ±‚è¶…æ—¶ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                            consecutive_failures += 1
                            break
                    except Exception as e:
                        retry_count += 1
                        if retry_count < max_retries:
                            print(f"ç¬¬{page}é¡µè·å–å¤±è´¥: {str(e)}, ç¬¬{retry_count}æ¬¡é‡è¯•...")
                            await asyncio.sleep(1.0)
                            continue
                        else:
                            print(f"ç¬¬{page}é¡µè·å–å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {str(e)}")
                            consecutive_failures += 1
                            break
                
                # å¦‚æœé‡è¯•åä»ç„¶å¤±è´¥ï¼Œè·³è¿‡å½“å‰é¡µç»§ç»­ä¸‹ä¸€é¡µ
                if not page_success and retry_count >= max_retries:
                    print(f"è·³è¿‡ç¬¬{page}é¡µï¼Œç»§ç»­ä¸‹ä¸€é¡µ...")
                    consecutive_failures += 1
                    page += 1
                    # å¦‚æœè¿ç»­å¤±è´¥å¤ªå¤šï¼Œå¯èƒ½æœ‰é—®é¢˜ï¼Œæå‰ç»“æŸ
                    if consecutive_failures >= 5:
                        print("è¿ç»­å¤±è´¥è¿‡å¤šï¼Œå¯èƒ½ç½‘ç»œæˆ–APIæœ‰é—®é¢˜ï¼Œåœæ­¢è·å–")
                        break
                    continue
                
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»“æŸå¾ªç¯
                if not page_success or interrupted:
                    break
                
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šé¡µ
                if len(items) < page_size:
                    # å½“å‰é¡µä¸æ»¡ï¼Œé€šå¸¸æ„å‘³ç€æ²¡æœ‰æ›´å¤šæ•°æ®
                    break
            
            pbar.close()
            current_count = len(all_items)
            print(f"è·å–å®Œæˆ: {current_count}/{media_count} é¡¹")
            
            # æ£€æŸ¥è·å–å®Œæ•´æ€§
            if current_count < media_count:
                if current_count == 0:
                    print("è­¦å‘Š: æœªèƒ½è·å–åˆ°ä»»ä½•æ”¶è—å¤¹å†…å®¹")
                elif current_count < media_count * 0.5:  # è·å–ä¸åˆ°ä¸€åŠ
                    print(f"è­¦å‘Š: è·å–ä¸å®Œæ•´ï¼Œåªè·å–åˆ°{current_count}é¡¹ï¼Œåº”æœ‰{media_count}é¡¹")
                else:
                    print(f"æç¤º: è·å–åˆ°{current_count}é¡¹ï¼Œåº”æœ‰{media_count}é¡¹")
            
            return all_items
        except Exception as e:
            print(f"\nè·å–æ”¶è—å¤¹è¯¦æƒ…å¤±è´¥: {str(e)}")
            return all_items

    def upgrade_database(self):
        """å‡çº§æ•°æ®åº“ç»“æ„æˆ–åˆ›å»ºæ–°æ•°æ®åº“"""
        if not self.db_exists:
            # é¦–æ¬¡è¿è¡Œæ—¶åˆ›å»ºæ•°æ®åº“
            print(f"\né¦–æ¬¡è¿è¡Œï¼Œåˆ›å»ºæ•°æ®åº“...")
            try:
                conn = sqlite3.connect(DB_FILE)
                c = conn.cursor()
                
                # åˆ›å»ºæ”¶è—å¤¹è¡¨
                c.execute("""
                CREATE TABLE IF NOT EXISTS favorites (
                    id INTEGER PRIMARY KEY,
                    title TEXT,
                    media_id INTEGER,
                    count INTEGER,
                    last_updated TEXT
                )
                """)
                
                # åˆ›å»ºæ”¶è—é¡¹è¡¨
                c.execute("""
                CREATE TABLE IF NOT EXISTS favorite_items (
                    id TEXT PRIMARY KEY,
                    favorite_id INTEGER,
                    title TEXT,
                    bvid TEXT,
                    owner_name TEXT,
                    FOREIGN KEY(favorite_id) REFERENCES favorites(id)
                )
                """)
                
                conn.commit()
                print("æ•°æ®åº“åˆ›å»ºæˆåŠŸ")
                self.db_exists = True
                self.first_run = True  # æ ‡è®°ä¸ºé¦–æ¬¡è¿è¡Œ
            except Exception as e:
                print(f"åˆ›å»ºæ•°æ®åº“å¤±è´¥: {str(e)}")
            finally:
                if conn:
                    conn.close()
            return
        
        # å·²æœ‰æ•°æ®åº“æ—¶çš„å‡çº§é€»è¾‘
        try:
            conn = sqlite3.connect(DB_FILE)
            c = conn.cursor()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰last_updatedåˆ—
            c.execute("PRAGMA table_info(favorites)")
            columns = [col[1] for col in c.fetchall()]
            if "last_updated" not in columns:
                print("æ£€æµ‹åˆ°æ—§ç‰ˆæ•°æ®åº“ï¼Œæ­£åœ¨å‡çº§...")
                # æ·»åŠ last_updatedåˆ—
                c.execute("ALTER TABLE favorites ADD COLUMN last_updated TEXT")
                # è®¾ç½®é»˜è®¤å€¼
                current_time = datetime.now().isoformat()
                c.execute("UPDATE favorites SET last_updated=?", (current_time,))
                print("æ•°æ®åº“å‡çº§å®Œæˆ")
            
            conn.commit()
        except Exception as e:
            print(f"æ•°æ®åº“å‡çº§å¤±è´¥: {str(e)}")
        finally:
            if conn:
                conn.close()

    async def save_to_db(self, data: List[Dict]) -> bool:
        """ä¿å­˜æ”¶è—å¤¹æ•°æ®åˆ°æ•°æ®åº“"""
        # ç¡®ä¿æ•°æ®åº“å­˜åœ¨ä¸”ç»“æ„æ­£ç¡®
        self.upgrade_database()
        
        conn = None
        try:
            conn = sqlite3.connect(DB_FILE)
            c = conn.cursor()
            
            # åœ¨ä¿å­˜æ‰€æœ‰æ•°æ®å‰è·å–å½“å‰æ—¶é—´
            current_time = datetime.now().isoformat()
            self.current_update_time = current_time
            
            total_items = 0
            
            # éå†æ‰€æœ‰æ”¶è—å¤¹
            for folder in data:
                # æ£€æŸ¥æ”¶è—å¤¹æ˜¯å¦å­˜åœ¨
                c.execute("SELECT 1 FROM favorites WHERE id=?", (folder["id"],))
                exists = c.fetchone()
                
                if exists:
                    # æ›´æ–°æ”¶è—å¤¹ä¿¡æ¯
                    c.execute(
                        "UPDATE favorites SET title=?, count=?, last_updated=? WHERE id=?",
                        (folder["title"], folder["media_count"], current_time, folder["id"])
                    )
                else:
                    # æ’å…¥æ–°æ”¶è—å¤¹
                    c.execute(
                        "INSERT INTO favorites (id, title, media_id, count, last_updated) VALUES (?, ?, ?, ?, ?)",
                        (folder["id"], folder["title"], folder["id"], folder["media_count"], current_time)
                    )
                
                # åˆ é™¤æ—§æ¡ç›®
                c.execute("DELETE FROM favorite_items WHERE favorite_id=?", (folder["id"],))
                
                # æ’å…¥æ”¶è—é¡¹
                for item in folder.get("items", []):
                    total_items += 1
                    owner = item.get("upper", {}).get("name", "æœªçŸ¥ä½œè€…") if "upper" in item else "æœªçŸ¥ä½œè€…"
                    bvid = item.get("bvid", "")
                    
                    # ä½¿ç”¨ç»„åˆID (æ”¶è—å¤¹ID_BVID)
                    item_id = f"{folder['id']}_{bvid}"
                    
                    # æ’å…¥æˆ–å¿½ç•¥é‡å¤é¡¹
                    c.execute(
                        "INSERT OR IGNORE INTO favorite_items (id, favorite_id, title, bvid, owner_name) VALUES (?, ?, ?, ?, ?)",
                        (item_id, folder["id"], item["title"], bvid, owner)
                    )
            
            conn.commit()
            print(f"æˆåŠŸä¿å­˜ {len(data)} ä¸ªæ”¶è—å¤¹ï¼Œå…±{total_items}ä¸ªé¡¹ç›®åˆ°æ•°æ®åº“")
            
            # æ›´æ–°æœ€åæ›´æ–°æ—¶é—´
            self.last_updated = datetime.fromisoformat(current_time)
            
            return True
        except sqlite3.IntegrityError as e:
            print(f"æ•°æ®åº“ä¿å­˜å¤±è´¥ (å”¯ä¸€çº¦æŸ): {str(e)}")
            return False
        except Exception as e:
            print(f"ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {str(e)}")
            return False
        finally:
            if conn:
                conn.close()

    def print_tree(self, data: List[Dict]):
        """æ‰“å°æ”¶è—å¤¹æ ‘å½¢ç»“æ„"""
        for folder in data:
            print(f"\nğŸ“ {folder['title']} ({folder['media_count']}é¡¹)")
            
            items = folder.get("items", [])
            # æœ€å¤šæ˜¾ç¤ºå‰20é¡¹
            for i, item in enumerate(items[:20]):
                prefix = "  â”œâ”€" if i < len(items)-1 else "  â””â”€"
                bvid = item.get("bvid", "æœªçŸ¥BVå·")
                owner = item.get("upper", {}).get("name", "æœªçŸ¥ä½œè€…") if "upper" in item else "æœªçŸ¥ä½œè€…"
                print(f"{prefix} {item['title']} {bvid} by {owner}")
            
            # å¦‚æœé¡¹ç›®è¶…è¿‡20ä¸ªï¼Œæ˜¾ç¤ºçœç•¥ä¿¡æ¯
            if len(items) > 20:
                print(f"  â””â”€ ...è¿˜æœ‰{len(items)-20}é¡¹æœªæ˜¾ç¤º")
            elif folder['media_count'] > len(items):
                print(f"  â””â”€ è·å–ä¸å®Œæ•´: åº”æœ‰{folder['media_count']}é¡¹ï¼Œå®é™…è·å–{len(items)}é¡¹")

    def get_favorite_videos(self, favorite_id: int) -> Tuple[str, List[Tuple[str, str]]]:
        """ä»æ•°æ®åº“è·å–æŒ‡å®šæ”¶è—å¤¹çš„è§†é¢‘åˆ—è¡¨"""
        try:
            conn = sqlite3.connect(DB_FILE)
            c = conn.cursor()
            
            # è·å–æ”¶è—å¤¹æ ‡é¢˜
            c.execute("SELECT title FROM favorites WHERE id=?", (favorite_id,))
            row = c.fetchone()
            folder_title = row[0] if row else f"æ”¶è—å¤¹_{favorite_id}"
            
            # è·å–æ”¶è—å¤¹ä¸­çš„è§†é¢‘
            c.execute("SELECT title, bvid FROM favorite_items WHERE favorite_id=?", (favorite_id,))
            videos = c.fetchall()
            return folder_title, videos
        except Exception as e:
            print(f"ä»æ•°æ®åº“è·å–æ”¶è—å¤¹è§†é¢‘å¤±è´¥: {str(e)}")
            return f"æ”¶è—å¤¹_{favorite_id}", []
        finally:
            if conn:
                conn.close()

    async def get_video_info(self, session: httpx.AsyncClient, bvid: str) -> Optional[Dict]:
        """è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯"""
        try:
            resp = await session.get(
                "https://api.bilibili.com/x/web-interface/view",
                params={"bvid": bvid},
                timeout=15.0
            )
            resp.raise_for_status()
            data = resp.json()
            if data.get("code") != 0:
                print(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {data.get('message')}")
                return None
            return data["data"]  # è¿”å›è§†é¢‘æ•°æ®
        except Exception as e:
            print(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {str(e)}")
            return None

    async def get_video_pages(self, session: httpx.AsyncClient, bvid: str) -> Optional[List[Dict]]:
        """è·å–è§†é¢‘çš„æ‰€æœ‰åˆ†Pä¿¡æ¯"""
        try:
            video_info = await self.get_video_info(session, bvid)
            if not video_info:
                return None
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªåˆ†P
            pages = video_info.get("pages", [])
            if len(pages) > 1:
                return pages
            else:
                # å•åˆ†Pè§†é¢‘ï¼Œè¿”å›åŒ…å«ä¸»åˆ†Pçš„åˆ—è¡¨
                return [{
                    "cid": video_info["cid"],
                    "page": 1,
                    "part": video_info.get("title", "ä¸»è§†é¢‘"),
                    "duration": video_info.get("duration", 0)
                }]
        except Exception as e:
            print(f"è·å–è§†é¢‘åˆ†Pä¿¡æ¯å¤±è´¥: {str(e)}")
            return None

    def parse_page_selection(self, input_str: str, total_pages: int, downloaded_indices: List[int] = None) -> Optional[List[int]]:
        """
        è§£æç”¨æˆ·çš„åˆ†Pé€‰æ‹©è¾“å…¥
        å‚æ•°:
            input_str: ç”¨æˆ·è¾“å…¥å­—ç¬¦ä¸²
            total_pages: æ€»åˆ†Pæ•°é‡
            downloaded_indices: å·²ä¸‹è½½çš„åˆ†Pç´¢å¼•åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        è¿”å›:
            List[int]: é€‰ä¸­çš„åˆ†Pç´¢å¼•åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºå–æ¶ˆ
        """
        if not input_str:
            return list(range(1, total_pages + 1))  # é»˜è®¤ä¸‹è½½æ‰€æœ‰
        
        input_str = input_str.strip().lower()
        
        # å¤„ç†ç‰¹æ®Šå‘½ä»¤
        if input_str in ['a', 'all', 'æ‰€æœ‰']:
            return list(range(1, total_pages + 1))
        elif input_str in ['c', 'cancel', 'å–æ¶ˆ']:
            return None
        elif input_str == 's':
            # è·³è¿‡æ‰€æœ‰å·²ä¸‹è½½åˆ†P
            if downloaded_indices:
                # è¿”å›æ‰€æœ‰æœªä¸‹è½½çš„åˆ†P
                all_indices = set(range(1, total_pages + 1))
                downloaded_set = set(downloaded_indices)
                selected = sorted(list(all_indices - downloaded_set))
                if not selected:
                    print("æ‰€æœ‰åˆ†Péƒ½å·²ä¸‹è½½ï¼Œæ²¡æœ‰éœ€è¦ä¸‹è½½çš„åˆ†P")
                    return []
                print(f"è·³è¿‡å·²ä¸‹è½½åˆ†Pï¼Œå°†ä¸‹è½½: {', '.join(map(str, selected))}")
                return selected
            else:
                print("æ²¡æœ‰å·²ä¸‹è½½åˆ†Pä¿¡æ¯ï¼Œå°†ä¸‹è½½æ‰€æœ‰åˆ†P")
                return list(range(1, total_pages + 1))
        
        # æ›¿æ¢ä¸­æ–‡é€—å·ä¸ºè‹±æ–‡é€—å·
        input_str = input_str.replace('ï¼Œ', ',')
        # æ›¿æ¢ä¸­æ–‡ç ´æŠ˜å·ä¸ºè‹±æ–‡è¿å­—ç¬¦
        input_str = input_str.replace('â€”', '-')
        
        selected_pages = set()
        
        try:
            # è§£æé€—å·åˆ†éš”çš„å¤šä¸ªé€‰æ‹©
            parts = input_str.split(',')
            for part in parts:
                part = part.strip()
                if not part:
                    continue
                    
                # æ£€æŸ¥æ˜¯å¦æ˜¯èŒƒå›´é€‰æ‹© (å¦‚: 1-5)
                if '-' in part:
                    range_parts = part.split('-')
                    if len(range_parts) == 2:
                        start = int(range_parts[0].strip())
                        end = int(range_parts[1].strip())
                        if 1 <= start <= total_pages and 1 <= end <= total_pages and start <= end:
                            selected_pages.update(range(start, end + 1))
                        else:
                            print(f"æ— æ•ˆèŒƒå›´: {part}")
                            return None
                    else:
                        print(f"æ— æ•ˆèŒƒå›´æ ¼å¼: {part}")
                        return None
                else:
                    # å•ä¸ªæ•°å­—
                    page_num = int(part)
                    if 1 <= page_num <= total_pages:
                        selected_pages.add(page_num)
                    else:
                        print(f"æ— æ•ˆåˆ†På·: {page_num}")
                        return None
                        
            return sorted(list(selected_pages))
            
        except ValueError:
            print("è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨æ•°å­—ã€é€—å·æˆ–è¿å­—ç¬¦")
            return None

    async def get_video_url(self, session: httpx.AsyncClient, bvid: str, cid: int, quality: int = 80) -> Optional[Dict]:
        """
        è·å–è§†é¢‘æ’­æ”¾URL
        å‚æ•°:
            bvid: è§†é¢‘BVå·
            cid: è§†é¢‘CID
            quality: æ¸…æ™°åº¦ä»£ç 
        è¿”å›:
            Dict: åŒ…å«è§†é¢‘å’ŒéŸ³é¢‘URLçš„å­—å…¸
        """
        # éä¼šå‘˜æ¸…æ™°åº¦é™åˆ¶
        if not self.is_member and quality > NON_MEMBER_MAX_QUALITY:
            quality = NON_MEMBER_MAX_QUALITY
        
        # å¯¹äº360På’Œæœ€ä½æ¸…æ™°åº¦ï¼Œä¸ä½¿ç”¨DASHæ ¼å¼
        use_dash = quality not in [16, 6]  # 16=360P, 6=æœ€ä½
        
        # æ˜¾ç¤ºä½¿ç”¨çš„æ ¼å¼
        format_type = "DASH" if use_dash else "FLV"
        
        # è·å–æ¸…æ™°åº¦æè¿°
        quality_desc = QUALITY_CODE_TO_DESC.get(quality, f"{quality} (æœªçŸ¥)")
        
        print(f"æ¸…æ™°åº¦: {quality_desc} ({format_type}æ ¼å¼)")
        
        try:
            # æ„å»ºè¯·æ±‚å‚æ•°
            params = {
                "bvid": bvid,
                "cid": cid,
                "qn": quality,
                "fnval": 4048 if use_dash else 0,  # ä½¿ç”¨DASHæ ¼å¼
                "fourk": 1,  # æ”¯æŒ4K
                "platform": "pc"
            }
            
            # è·å–æ’­æ”¾URL
            resp = await session.get(
                "https://api.bilibili.com/x/player/playurl",
                params=params,
                timeout=15.0
            )
            resp.raise_for_status()
            data = resp.json()
            
            if data.get("code") != 0:
                # å›é€€åˆ°éDASHæ ¼å¼
                params["fnval"] = 0
                resp = await session.get(
                    "https://api.bilibili.com/x/player/playurl",
                    params=params,
                    timeout=15.0
                )
                resp.raise_for_status()
                data = resp.json()
                if data.get("code") != 0:
                    return None
                
                # è¿”å›FLVæ ¼å¼URL
                return {
                    "video_url": data["data"]["durl"][0]["url"],
                    "audio_url": None,  # éDASHæ ¼å¼åŒ…å«éŸ³é¢‘
                    "format": "flv"
                }
            
            # å¤„ç†DASHæ ¼å¼
            dash_data = data["data"].get("dash")
            if dash_data and use_dash:
                # è·å–è§†é¢‘æµ
                video_streams = dash_data.get("video", [])
                selected_video = None
                for stream in video_streams:
                    if stream.get("id") == quality:
                        selected_video = stream
                        break
                # å¦‚æœæ²¡æœ‰åŒ¹é…çš„qualityï¼Œé€‰æ‹©æœ€é«˜è´¨é‡çš„è§†é¢‘æµ
                if not selected_video and video_streams:
                    video_streams.sort(key=lambda x: x.get("id", 0), reverse=True)
                    selected_video = video_streams[0]
                
                # è·å–éŸ³é¢‘æµ
                audio_streams = dash_data.get("audio", [])
                selected_audio = None
                if audio_streams:
                    # é€‰æ‹©æœ€é«˜è´¨é‡çš„éŸ³é¢‘æµ
                    audio_streams.sort(key=lambda x: x.get("bandwidth", 0), reverse=True)
                    selected_audio = audio_streams[0]
                
                if selected_video and selected_audio:
                    return {
                        "video_url": selected_video["baseUrl"],
                        "audio_url": selected_audio["baseUrl"],
                        "format": "dash"
                    }
            
            # éDASHæ ¼å¼æˆ–è·å–å¤±è´¥
            return {
                "video_url": data["data"]["durl"][0]["url"],
                "audio_url": None,
                "format": "flv"
            }
        except Exception as e:
            print(f"è·å–è§†é¢‘URLå¤±è´¥: {str(e)}")
            return None

    async def download_file(self, url: str, file_path: str, title: str, file_type: str, headers: Dict) -> bool:
        """
        å¼‚æ­¥ä¸‹è½½æ–‡ä»¶
        å‚æ•°:
            url: æ–‡ä»¶URL
            file_path: æœ¬åœ°ä¿å­˜è·¯å¾„
            title: æ–‡ä»¶æ ‡é¢˜(ç”¨äºæ˜¾ç¤º)
            file_type: æ–‡ä»¶ç±»å‹(è§†é¢‘/éŸ³é¢‘)
            headers: HTTPè¯·æ±‚å¤´
        è¿”å›:
            bool: ä¸‹è½½æ˜¯å¦æˆåŠŸ
        """
        try:
            # éŸ³é¢‘ä¸‹è½½æ¢è¡Œæ˜¾ç¤º
            if file_type == "éŸ³é¢‘":
                print(f"\nå¼€å§‹ä¸‹è½½{file_type}: {title}")
            else:
                print(f"\nå¼€å§‹ä¸‹è½½{file_type}: {title}")
    
            async with httpx.AsyncClient(headers=headers, timeout=60.0) as client:
                # æµå¼ä¸‹è½½
                async with client.stream("GET", url, follow_redirects=True) as response:
                    response.raise_for_status()
                    total_size = int(response.headers.get("Content-Length", 0))
            
                    # å¤„ç†æ— æ•ˆçš„æ–‡ä»¶å¤§å°
                    if total_size <= 0:
                        # å°è¯•ä»Content-Rangeå¤´è·å–æ–‡ä»¶å¤§å°
                        if "Content-Range" in response.headers:
                            try:
                                total_size = int(response.headers["Content-Range"].split("/")[-1])
                            except:
                                # å¦‚æœæ— æ³•ç¡®å®šæ–‡ä»¶å¤§å°ï¼Œä½¿ç”¨é»˜è®¤å€¼
                                total_size = 1024 * 1024  # 1MB
                        else:
                            total_size = 1024 * 1024  # 1MB
            
                    # åˆ›å»ºè¿›åº¦æ¡
                    pbar = tqdm(
                        total=total_size,
                        desc=f"{file_type}ä¸‹è½½: {title[:30]}",  # é™åˆ¶æ ‡é¢˜é•¿åº¦
                        unit="B",
                        unit_scale=True,
                        unit_divisor=1024,
                        miniters=1,
                        leave=True,  # å®Œæˆåä¸ä¿ç•™æ˜¾ç¤º
                        mininterval=0.1  # æœ€å°æ›´æ–°é—´éš”
                    )
            
                    try:
                        # åˆå§‹åŒ–è¿›åº¦æ¡
                        pbar.update(0)
                    
                        # ä¸‹è½½æ–‡ä»¶
                        downloaded_size = 0
                        with open(file_path, "wb") as f:
                            async for chunk in response.aiter_bytes(chunk_size=8192):
                                if interrupted:  # æ£€æŸ¥ä¸­æ–­
                                    return False
                                f.write(chunk)
                                chunk_size = len(chunk)
                                pbar.update(chunk_size)
                                downloaded_size += chunk_size
                    
                        # ç¡®ä¿è¿›åº¦æ¡å®Œæˆ
                        if downloaded_size < total_size:
                            pbar.update(total_size - downloaded_size)
                    
                        return True
                    finally:
                        # å…³é—­è¿›åº¦æ¡
                        pbar.close()
            
        except Exception as e:
            print(f"ä¸‹è½½{file_type}å¤±è´¥: {title} - {str(e)}")
            # åˆ é™¤ä¸å®Œæ•´çš„æ–‡ä»¶
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                except:
                    pass
            return False

    async def download_single_video(self, session: httpx.AsyncClient, bvid: str, title: str, output_path: str, quality: int, overwrite: bool = False) -> bool:
        """
        ä¸‹è½½å•ä¸ªè§†é¢‘
        å‚æ•°:
            session: HTTPä¼šè¯
            bvid: è§†é¢‘BVå·
            title: è§†é¢‘æ ‡é¢˜
            output_path: è¾“å‡ºç›®å½•
            quality: æ¸…æ™°åº¦ä»£ç 
            overwrite: æ˜¯å¦è¦†ç›–å·²å­˜åœ¨æ–‡ä»¶
        è¿”å›:
            bool: ä¸‹è½½æ˜¯å¦æˆåŠŸ
        """
        global interrupted
        
        try:
            # è·å–è§†é¢‘çš„æ‰€æœ‰åˆ†Pä¿¡æ¯
            pages = await self.get_video_pages(session, bvid)
            if not pages:
                print(f"è·³è¿‡è§†é¢‘: {title} ({bvid}) - æ— æ³•è·å–è§†é¢‘ä¿¡æ¯")
                return False
            
            # å¦‚æœæ˜¯å¤šåˆ†Pè§†é¢‘ï¼Œè®©ç”¨æˆ·é€‰æ‹©è¦ä¸‹è½½çš„åˆ†P
            selected_cids = []
            if len(pages) > 1:
                print(f"\næ£€æµ‹åˆ°å¤šåˆ†Pè§†é¢‘: {title} ({bvid})")
                
                # æ£€æŸ¥å·²ä¸‹è½½çš„åˆ†P
                downloaded_indices = []
                for i, page in enumerate(pages, 1):
                    part_title = page.get("part", f"åˆ†P{i}")
                    safe_title = sanitize_filename(part_title)
                    safe_title = shorten_filename(safe_title)
                    file_path = os.path.join(output_path, f"{safe_title}_{bvid}.mp4")
                    if os.path.exists(file_path):
                        downloaded_indices.append(i)
                
                print("åˆ†Påˆ—è¡¨:")
                for i, page in enumerate(pages, 1):
                    duration_min = page.get("duration", 0) // 60
                    duration_sec = page.get("duration", 0) % 60
                    part_title = page.get("part", f"åˆ†P{i}")
                    # æ ‡è®°å·²ä¸‹è½½çš„åˆ†P
                    if i in downloaded_indices:
                        print(f"  {i}. {part_title} ({duration_min}:{duration_sec:02d}) [å·²ä¸‹è½½]")
                    else:
                        print(f"  {i}. {part_title} ({duration_min}:{duration_sec:02d})")
                
                print("\nè¯·é€‰æ‹©è¦ä¸‹è½½çš„åˆ†P:")
                print("  [a/æ‰€æœ‰/all] ä¸‹è½½æ‰€æœ‰åˆ†P")
                print("  [c/å–æ¶ˆ/cancel] å–æ¶ˆä¸‹è½½")
                print("  [s] è·³è¿‡æ‰€æœ‰å·²ä¸‹è½½åˆ†P")
                print("  [æ•°å­—] ä¸‹è½½æŒ‡å®šåˆ†P (å¦‚: 1, 2, 3)")
                print("  [èŒƒå›´] ä¸‹è½½èŒƒå›´åˆ†P (å¦‚: 1-5)")
                print("  [æ··åˆ] æ··åˆé€‰æ‹© (å¦‚: 1,3,5-7)")
                print("è¯·è¾“å…¥é€‰æ‹© (é»˜è®¤ä¸‹è½½æ‰€æœ‰): ", end="", flush=True)
                
                choice = input().strip()
                
                # è§£æç”¨æˆ·é€‰æ‹©ï¼Œä¼ å…¥å·²ä¸‹è½½åˆ†Pä¿¡æ¯
                selected_indices = self.parse_page_selection(choice, len(pages), downloaded_indices)
                
                if selected_indices is None:
                    if choice and choice not in ['c', 'cancel', 'å–æ¶ˆ']:
                        print("è¾“å…¥æ— æ•ˆï¼Œå°†ä¸‹è½½æ‰€æœ‰åˆ†P")
                        selected_indices = list(range(1, len(pages) + 1))
                    else:
                        print("å–æ¶ˆä¸‹è½½")
                        return False
                
                # æ ¹æ®é€‰æ‹©çš„ç´¢å¼•è·å–å¯¹åº”çš„åˆ†P
                selected_cids = [(pages[idx-1]["cid"], pages[idx-1].get("part", f"åˆ†P{idx}")) for idx in selected_indices]
                print(f"å°†ä¸‹è½½ {len(selected_cids)} ä¸ªåˆ†P: {', '.join(map(str, selected_indices))}")
            else:
                # å•åˆ†Pè§†é¢‘
                selected_cids = [(pages[0]["cid"], title)]
            
            # ä¸‹è½½é€‰ä¸­çš„åˆ†P
            success_count = 0
            for cid, part_title in selected_cids:
                if interrupted:
                    break
                
                # ä¸ºæ¯ä¸ªåˆ†Pç”Ÿæˆç‹¬ç«‹çš„æ–‡ä»¶å
                safe_title = sanitize_filename(part_title)
                safe_title = shorten_filename(safe_title)
                file_path = os.path.join(output_path, f"{safe_title}_{bvid}.mp4")
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆå³ä½¿ä¸åœ¨å·²ä¸‹è½½åˆ—è¡¨ä¸­ï¼‰
                if os.path.exists(file_path):
                    if overwrite:
                        try:
                            os.remove(file_path)
                            print(f"å·²åˆ é™¤æ—§æ–‡ä»¶: {part_title} ({bvid})")
                        except Exception as e:
                            print(f"åˆ é™¤æ—§æ–‡ä»¶å¤±è´¥: {part_title} ({bvid}) - {str(e)}")
                            continue
                    else:
                        print(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {part_title} ({bvid})")
                        continue
                
                # è·å–åª’ä½“URL
                media_info = await self.get_video_url(session, bvid, cid, quality)
                if not media_info:
                    print(f"è·³è¿‡åˆ†P: {part_title} ({bvid}) - æ— æ³•è·å–ä¸‹è½½é“¾æ¥")
                    continue
                
                # åˆ›å»ºè¾“å‡ºç›®å½•
                os.makedirs(output_path, exist_ok=True)
                
                # æ„å»ºè¯·æ±‚å¤´
                headers = {
                    "User-Agent": HEADERS["User-Agent"],
                    "Referer": "https://www.bilibili.com",
                    "Cookie": "; ".join([f"{k}={v}" for k, v in session.cookies.items()])
                }
                
                # ä¸‹è½½è§†é¢‘æ–‡ä»¶
                video_url = media_info["video_url"]
                video_file = os.path.join(output_path, f"{safe_title}_{bvid}_video.tmp")
                
                # ä¸‹è½½è§†é¢‘
                video_success = await self.download_file(
                    video_url, video_file, part_title, "è§†é¢‘", headers
                )
                
                if not video_success:
                    continue
                
                # ä¸‹è½½éŸ³é¢‘æ–‡ä»¶ï¼ˆå¦‚æœæ˜¯DASHæ ¼å¼ï¼‰
                audio_file = None
                audio_success = True
                
                if media_info["audio_url"] and self.ffmpeg_available:
                    audio_url = media_info["audio_url"]
                    audio_file = os.path.join(output_path, f"{safe_title}_{bvid}_audio.tmp")
                    
                    # ä¸‹è½½éŸ³é¢‘
                    audio_success = await self.download_file(
                        audio_url, audio_file, part_title, "éŸ³é¢‘", headers
                    )
                
                # å¤„ç†éŸ³é¢‘ä¸‹è½½å¤±è´¥æƒ…å†µ
                if not audio_success:
                    if os.path.exists(video_file):
                        try:
                            os.rename(video_file, file_path)
                            print(f"éŸ³é¢‘ä¸‹è½½å¤±è´¥ï¼Œå·²ä¿å­˜è§†é¢‘æ–‡ä»¶: {part_title}")
                            success_count += 1
                        except Exception as e:
                            print(f"é‡å‘½åè§†é¢‘æ–‡ä»¶å¤±è´¥: {part_title} - {str(e)}")
                    continue
                
                # å¤„ç†éŸ³è§†é¢‘åˆå¹¶
                if audio_file and os.path.exists(audio_file):
                    # åŠ å…¥åˆå¹¶é˜Ÿåˆ—
                    if self.queue_merge_task(video_file, audio_file, file_path, part_title, bvid):
                        success_count += 1
                else:
                    # éDASHæ ¼å¼ï¼Œç›´æ¥é‡å‘½åè§†é¢‘æ–‡ä»¶
                    if os.path.exists(video_file):
                        try:
                            os.rename(video_file, file_path)
                            print(f"ä¸‹è½½å®Œæˆ: {part_title} ({bvid})")
                            success_count += 1
                        except Exception as e:
                            print(f"é‡å‘½åè§†é¢‘æ–‡ä»¶å¤±è´¥: {part_title} - {str(e)}")
            
            return success_count > 0
            
        except Exception as e:
            print(f"ä¸‹è½½å¤±è´¥: {title} ({bvid}) - {str(e)}")
            return False

    async def download_favorite_videos(self, session: httpx.AsyncClient, favorite_id: int, output_dir: str, quality: str):
        """
        ä¸‹è½½æŒ‡å®šæ”¶è—å¤¹çš„æ‰€æœ‰è§†é¢‘
        å‚æ•°:
            session: HTTPä¼šè¯
            favorite_id: æ”¶è—å¤¹ID
            output_dir: è¾“å‡ºç›®å½•
            quality: æ¸…æ™°åº¦æè¿°å­—ç¬¦ä¸²
        """
        global interrupted, overwrite_all, skip_existing
    
        # è·å–æ”¶è—å¤¹ä¿¡æ¯
        folder_title, videos = self.get_favorite_videos(favorite_id)
        if not videos:
            print("è¯¥æ”¶è—å¤¹ä¸­æ²¡æœ‰è§†é¢‘")
            return
    
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = os.path.join(output_dir, folder_title)
        os.makedirs(output_path, exist_ok=True)
    
        print(f"å¼€å§‹ä¸‹è½½æ”¶è—å¤¹: {folder_title} ({len(videos)}ä¸ªè§†é¢‘)")
        print(f"ä¸‹è½½è·¯å¾„: {output_path}")
        print(f"æ¸…æ™°åº¦: {quality}")
    
        # æ˜¾ç¤ºFFmpegçŠ¶æ€
        if self.ffmpeg_available:
            print(f"FFmpegå¯ç”¨ (ç‰ˆæœ¬: {self.ffmpeg_version})")
        else:
            print("FFmpegä¸å¯ç”¨ï¼ŒDASHæ ¼å¼è§†é¢‘å°†æ— æ³•åˆå¹¶éŸ³é¢‘")
    
        # è·å–æ¸…æ™°åº¦ä»£ç 
        quality_code = QUALITY_MAP.get(quality, 80)
    
        # é‡ç½®å…¨å±€æ ‡å¿—
        overwrite_all = False
        skip_existing = False
    
        download_tasks = []  # ä¸‹è½½ä»»åŠ¡åˆ—è¡¨
        skipped_count = 0    # è·³è¿‡çš„è§†é¢‘æ•°
        overwritten_count = 0 # è¦†ç›–çš„è§†é¢‘æ•°
        new_videos = 0       # æ–°å¢çš„è§†é¢‘æ•°
    
        # éå†æ‰€æœ‰è§†é¢‘ï¼Œå¤„ç†æ–‡ä»¶å­˜åœ¨æƒ…å†µ
        for title, bvid in videos:
            if interrupted:
                break
            
            # æ„å»ºå®‰å…¨æ–‡ä»¶å
            safe_title = sanitize_filename(title)
            safe_title = shorten_filename(safe_title)
            file_path = os.path.join(output_path, f"{safe_title}_{bvid}.mp4")
            file_exists = os.path.exists(file_path)
        
            # å¤„ç†è·³è¿‡æ‰€æœ‰å·²å­˜åœ¨æ–‡ä»¶çš„æƒ…å†µ
            if file_exists and skip_existing:
                skipped_count += 1
                continue
            
            # å¤„ç†è¦†ç›–æ‰€æœ‰æ–‡ä»¶çš„æƒ…å†µ
            if file_exists and overwrite_all:
                download_tasks.append((bvid, title, True))
                overwritten_count += 1
                continue
            
            # æ–‡ä»¶å­˜åœ¨ä¸”æœªè®¾ç½®å…¨å±€æ ‡å¿—ï¼Œè¯¢é—®ç”¨æˆ·
            if file_exists and not overwrite_all and not skip_existing:
                print(f"\nè§†é¢‘å·²å­˜åœ¨: {title} ({bvid})")
                print("è¯·é€‰æ‹©æ“ä½œ: [s]è·³è¿‡, [o]è¦†ç›–, [a]è¦†ç›–æ‰€æœ‰, [sa]è·³è¿‡æ‰€æœ‰, [c]å–æ¶ˆ (é»˜è®¤s): ", end='', flush=True)
                choice = input().strip().lower()
                if not choice:
                    choice = "s"
            
                if choice == "s":
                    skipped_count += 1
                    print("è·³è¿‡ä¸‹è½½")
                    continue
                elif choice == "o":
                    download_tasks.append((bvid, title, True))
                    overwritten_count += 1
                elif choice == "a":
                    download_tasks.append((bvid, title, True))
                    overwrite_all = True
                    overwritten_count += 1
                elif choice == "sa":
                    skip_existing = True
                    skipped_count += 1
                    print("è·³è¿‡æ‰€æœ‰å·²å­˜åœ¨è§†é¢‘")
                    continue
                elif choice == "c":
                    interrupted = True
                    break
                else:
                    skipped_count += 1
                    print("æ— æ•ˆé€‰é¡¹ï¼Œè·³è¿‡ä¸‹è½½")
                    continue
        
            # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ·»åŠ åˆ°ä¸‹è½½ä»»åŠ¡
            if not file_exists:
                download_tasks.append((bvid, title, False))
                new_videos += 1
        
        # æ˜¾ç¤ºå¤„ç†ç»“æœ
        print(f"\nä¸‹è½½ä»»åŠ¡ç»Ÿè®¡:")
        print(f" - è·³è¿‡: {skipped_count} ä¸ªå·²å­˜åœ¨è§†é¢‘")
        print(f" - è¦†ç›–: {overwritten_count} ä¸ªè§†é¢‘")
        print(f" - æ–°å¢: {new_videos} ä¸ªæ–°è§†é¢‘")
        print(f" - æ€»è®¡: {len(download_tasks)} ä¸ªè§†é¢‘éœ€è¦ä¸‹è½½")
    
        if not download_tasks:
            print("æ²¡æœ‰éœ€è¦ä¸‹è½½çš„è§†é¢‘")
            return
    
        # æ‰§è¡Œä¸‹è½½ä»»åŠ¡
        results = []
        for i, (bvid, title, overwrite) in enumerate(download_tasks, 1):
            if interrupted:
                break
            
            print(f"\n[{i}/{len(download_tasks)}] å¼€å§‹å¤„ç†è§†é¢‘: {title} ({bvid})")
            result = await self.download_single_video(
                session, bvid, title, output_path, quality_code, overwrite
            )
            results.append(result)
    
        # ç­‰å¾…åˆå¹¶é˜Ÿåˆ—å®Œæˆ
        while self.merge_queue and not interrupted:
            queue_size = len(self.merge_queue)
            print(f"ç­‰å¾…åˆå¹¶é˜Ÿåˆ—å®Œæˆ: å‰©ä½™ {queue_size} ä¸ªä»»åŠ¡...")
            if queue_size > 0:
                print(f"ä¸‹ä¸€ä¸ªä»»åŠ¡: {self.merge_queue[0][3]} ({self.merge_queue[0][4]})")
            await asyncio.sleep(5)
    
        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in results if r)
        failed_count = len(results) - success_count
    
        # æ‰“å°æœ€ç»ˆç»“æœ
        if not interrupted:
            print(f"\næ”¶è—å¤¹ä¸‹è½½å®Œæˆ: {folder_title}")
            print(f" - æˆåŠŸ: {success_count} ä¸ªè§†é¢‘")
            if failed_count > 0:
                print(f" - å¤±è´¥: {failed_count} ä¸ªè§†é¢‘")
            if skipped_count > 0:
                print(f" - è·³è¿‡: {skipped_count} ä¸ªå·²å­˜åœ¨è§†é¢‘")
            if new_videos > 0:
                print(f" - æ–°å¢: {new_videos} ä¸ªæ–°è§†é¢‘")

    async def fetch_and_update_favorites(self, session: httpx.AsyncClient) -> bool:
        """
        è·å–å¹¶æ›´æ–°æ”¶è—å¤¹æ•°æ®
        å‚æ•°:
            session: HTTPä¼šè¯
        è¿”å›:
            bool: æ“ä½œæ˜¯å¦æˆåŠŸ
        """
        global interrupted
        
        # å‡çº§æ•°æ®åº“ç»“æ„
        self.upgrade_database()
        
        # å†³å®šæ˜¯å¦æ›´æ–°æ•°æ®
        default_choice = "n"
        update_reason = ""
        
        # é¦–æ¬¡è¿è¡Œå¼ºåˆ¶æ›´æ–°
        if self.first_run:
            default_choice = "y"
            update_reason = " (é¦–æ¬¡è¿è¡Œéœ€è¦åŒæ­¥æ”¶è—å¤¹)"
            print(f"\né¦–æ¬¡è¿è¡Œï¼Œéœ€è¦åŒæ­¥æ”¶è—å¤¹...")
        
        # æ•°æ®åº“è¶…è¿‡24å°æ—¶æœªæ›´æ–°
        elif self.last_updated:
            time_diff = datetime.now() - self.last_updated
            if time_diff > timedelta(hours=24):
                default_choice = "y"
                update_reason = f" (æ•°æ®åº“å·²è¶…è¿‡24å°æ—¶æœªæ›´æ–°ï¼Œæœ€åæ›´æ–°äº {self.last_updated.strftime('%Y-%m-%d %H:%M')})"
        
        # è¯¢é—®ç”¨æˆ·æ˜¯å¦æ›´æ–°
        if self.db_exists and not self.first_run:
            print("\næ£€æµ‹åˆ°æœ¬åœ°æ•°æ®åº“å­˜åœ¨")
            
            update = input(f"æ˜¯å¦æ›´æ–°æ”¶è—å¤¹æ•°æ®? (y/n, é»˜è®¤{default_choice}{update_reason}): ").strip().lower() or default_choice
            
            if update == "y":
                print("ä»Bç«™APIè·å–æœ€æ–°æ”¶è—å¤¹æ•°æ®...")
            else:
                print("ä½¿ç”¨æœ¬åœ°æ•°æ®åº“æ•°æ®")
                return self.load_from_db()  # ä»æ•°æ®åº“åŠ è½½
        else:
            print("ä»Bç«™APIè·å–æ”¶è—å¤¹æ•°æ®...")
        
        # è·å–æ”¶è—å¤¹åˆ—è¡¨
        favorites = await self.get_favorites(session)
        if not favorites:
            return False
        
        # è·å–æ¯ä¸ªæ”¶è—å¤¹çš„è¯¦ç»†å†…å®¹
        self.all_data = []
        for fav in favorites:
            if interrupted:
                break
                
            # éšæœºå»¶è¿Ÿé˜²æ­¢è¯·æ±‚è¿‡å¿«
            delay = random.uniform(0.1, 0.8)
            await asyncio.sleep(delay)
            
            print(f"\næ­£åœ¨è·å–æ”¶è—å¤¹: {fav['title']} (ID: {fav['id']}, åº”æœ‰ {fav['media_count']} é¡¹)")
            
            try:
                # è·å–æ”¶è—å¤¹å†…å®¹
                items = await self.get_favorite_detail(session, fav["id"], fav["media_count"])
                self.all_data.append({
                    "id": fav["id"],
                    "title": fav["title"],
                    "media_count": fav["media_count"],
                    "items": items
                })
            except Exception as e:
                print(f"  â””â”€ è·å–å¤±è´¥: {str(e)}")
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        if not interrupted and self.all_data:
            success = await self.save_to_db(self.all_data)
            self.first_run = False  # é‡ç½®é¦–æ¬¡è¿è¡Œæ ‡å¿—
            return success
        else:
            return False

    def load_from_db(self) -> bool:
        """ä»æ•°æ®åº“åŠ è½½æ”¶è—å¤¹æ•°æ®"""
        try:
            conn = sqlite3.connect(DB_FILE)
            c = conn.cursor()
            
            # æŸ¥è¯¢æ”¶è—å¤¹
            c.execute("SELECT id, title, media_id, count, last_updated FROM favorites")
            folders = c.fetchall()
            
            self.all_data = []
            # å¤„ç†æ¯ä¸ªæ”¶è—å¤¹
            for folder in folders:
                # æŸ¥è¯¢æ”¶è—é¡¹
                c.execute("SELECT title, bvid, owner_name FROM favorite_items WHERE favorite_id=?", (folder[0],))
                items_rows = c.fetchall()
                items = [
                    {
                        "title": row[0],
                        "bvid": row[1],
                        "upper": {"name": row[2]}  # æ„å»ºç±»ä¼¼APIçš„ç»“æ„
                    }
                    for row in items_rows
                ]
                
                # æ·»åŠ åˆ°æ•°æ®åˆ—è¡¨
                self.all_data.append({
                    "id": folder[0],
                    "title": folder[1],
                    "media_id": folder[2],
                    "media_count": folder[3],
                    "last_updated": folder[4],
                    "items": items
                })
            
            print(f"æˆåŠŸåŠ è½½ {len(self.all_data)} ä¸ªæ”¶è—å¤¹")
            return True
        except Exception as e:
            print(f"æ•°æ®åº“åŠ è½½å¤±è´¥: {str(e)}")
            return False
        finally:
            if conn:
                conn.close()

    async def run(self):
        """ä¸‹è½½å™¨ä¸»è¿è¡Œæ–¹æ³•"""
        global interrupted
        
        # æ‰“å°æ¬¢è¿ä¿¡æ¯
        print("="*50)
        print("Bç«™æ”¶è—å¤¹è§†é¢‘ä¸‹è½½å™¨")
        print("="*50)
        print("æ­£åœ¨åˆå§‹åŒ–...")
        
        # åˆå§‹åŒ–ä¸‹è½½å™¨
        try:
            init_result = await self.initialize()
            if not init_result:
                print("åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•")
                # æä¾›æ›´å¤šè°ƒè¯•ä¿¡æ¯
                if not self.token_data:
                    print("åŸå› ï¼šæœªè·å–åˆ°æœ‰æ•ˆçš„ç™»å½•ä¿¡æ¯")
                elif not self.cookies:
                    print("åŸå› ï¼šæœªæ­£ç¡®è®¾ç½®Cookies")
                return
        except Exception as e:
            print(f"åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            return
        
        # æ£€æŸ¥ä¸­æ–­
        if interrupted:
            print("åˆå§‹åŒ–åæ£€æµ‹åˆ°ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
            return
            
        # åˆ›å»ºHTTPä¼šè¯
        async with httpx.AsyncClient(
            headers=HEADERS,
            cookies=self.cookies,
            timeout=60.0
        ) as session:
            # å†æ¬¡æ£€æŸ¥ä¸­æ–­
            if interrupted:
                print("åˆå§‹åŒ–åæ£€æµ‹åˆ°ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
                return
                
            # ä¸»æ“ä½œå¾ªç¯
            while not interrupted:
                print("\nè¯·é€‰æ‹©æ“ä½œ: 1. ä¸‹è½½æ”¶è—å¤¹è§†é¢‘  2. ç›´æ¥ä¸‹è½½è§†é¢‘  3. é€€å‡º")
                print("è¯·è¾“å…¥é€‰é¡¹ (é»˜è®¤1): ", end="")
                
                choice = input().strip()
                if not choice:
                    choice = "1"
                
                if choice == "1":
                    # è·å–å¹¶æ›´æ–°æ”¶è—å¤¹æ•°æ®
                    success = await self.fetch_and_update_favorites(session)
                    
                    if interrupted:
                        print("è·å–æ”¶è—å¤¹åæ£€æµ‹åˆ°ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
                        break
                        
                    # æ˜¾ç¤ºæ”¶è—å¤¹å†…å®¹
                    if success and self.all_data:
                        print("\næ”¶è—å¤¹å†…å®¹:")
                        self.print_tree(self.all_data)
                        
                        # æ˜¾ç¤ºæ”¶è—å¤¹åˆ—è¡¨
                        print("\næ”¶è—å¤¹åˆ—è¡¨:")
                        for folder in self.all_data:
                            print(f"ID: {folder['id']} - {folder['title']} ({folder['media_count']}é¡¹)")
                        
                        # è·å–ç”¨æˆ·é€‰æ‹©çš„æ”¶è—å¤¹ID
                        print("\nè¯·è¾“å…¥è¦ä¸‹è½½çš„æ”¶è—å¤¹ID: ", end="")
                        fav_id = input().strip()
                        if not fav_id.isdigit():
                            print("è¾“å…¥é”™è¯¯ï¼Œè¯·é‡æ–°è¾“å…¥")
                            continue
                        fav_id = int(fav_id)
                        
                        # éªŒè¯æ”¶è—å¤¹IDæ˜¯å¦å­˜åœ¨
                        found = False
                        for folder in self.all_data:
                            if folder['id'] == fav_id:
                                found = True
                                break
                        if not found:
                            print("æ”¶è—å¤¹IDä¸å­˜åœ¨")
                            continue
                        
                        # åˆ›å»ºæ¸…æ™°åº¦é€‰é¡¹åˆ—è¡¨
                        quality_options = list(QUALITY_MAP.keys())
                        
                        # æ˜¾ç¤ºæ¸…æ™°åº¦é€‰é¡¹
                        print("\nå¯ç”¨æ¸…æ™°åº¦:")
                        for i, q in enumerate(quality_options, 1):
                            print(f"{i}. {q}")
                        
                        # è·å–ç”¨æˆ·é€‰æ‹©çš„æ¸…æ™°åº¦
                        default_quality_index = quality_options.index('1080P') + 1 if '1080P' in quality_options else 4
                        print(f"è¯·é€‰æ‹©æ¸…æ™°åº¦ (1-{len(quality_options)}, é»˜è®¤{default_quality_index}): ", end="")
                        quality_choice = input().strip()
                        
                        # å¤„ç†é»˜è®¤å€¼
                        if not quality_choice:
                            quality_choice = str(default_quality_index)
                        
                        # éªŒè¯å¹¶è·å–æ¸…æ™°åº¦
                        if quality_choice.isdigit():
                            choice_index = int(quality_choice) - 1
                            if 0 <= choice_index < len(quality_options):
                                quality = quality_options[choice_index]
                            else:
                                print(f"è¾“å…¥è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨é»˜è®¤{quality_options[default_quality_index-1]}")
                                quality = quality_options[default_quality_index-1]
                        else:
                            print(f"æ— æ•ˆè¾“å…¥ï¼Œä½¿ç”¨é»˜è®¤{quality_options[default_quality_index-1]}")
                            quality = quality_options[default_quality_index-1]
                        
                        # éä¼šå‘˜æ¸…æ™°åº¦è°ƒæ•´
                        if not self.is_member and QUALITY_MAP.get(quality, 0) > NON_MEMBER_MAX_QUALITY:
                            print(f"æ™®é€šè´¦å·æœ€é«˜æ”¯æŒ1080Pï¼Œå·²è‡ªåŠ¨è°ƒæ•´ä¸º1080P")
                            quality = "1080P"
                        
                        # è·å–è¾“å‡ºç›®å½•
                        print("è¯·è¾“å…¥ä¸‹è½½è·¯å¾„ (é»˜è®¤./favourite_download): ", end="")
                        output_dir = input().strip() or "./favourite_download"
                        
                        # å¼€å§‹ä¸‹è½½
                        if interrupted:
                            print("å¼€å§‹ä¸‹è½½å‰æ£€æµ‹åˆ°ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
                            break
                        
                        await self.download_favorite_videos(session, fav_id, output_dir, quality)
                    else:
                        print("æœªèƒ½è·å–æ”¶è—å¤¹æ•°æ®")
                elif choice == "2":
                    await self.download_single_video_direct(session)
                elif choice == "3":
                    print("é€€å‡ºç¨‹åº")
                    break
                else:
                    print("æ— æ•ˆé€‰é¡¹ï¼Œè¯·é‡æ–°è¾“å…¥")
    
        # åœæ­¢åˆå¹¶çº¿ç¨‹
        self.stop_merge_thread()

    def extract_bvid_from_input(self, input_str: str) -> Optional[str]:
        """
        ä»ç”¨æˆ·è¾“å…¥ä¸­æå–BVå·
        æ”¯æŒæ ¼å¼:
        - BVå·: BV1zsnBzGEzC
        - å®Œæ•´é“¾æ¥: https://www.bilibili.com/video/BV1zsnBzGEzC/
        - å®Œæ•´é“¾æ¥: www.bilibili.com/video/BV1zsnBzGEzC/
        - éƒ¨åˆ†é“¾æ¥: bilibili.com/video/BV1zsnBzGEzC
        - éƒ¨åˆ†é“¾æ¥: /video/BV1zsnBzGEzC
        - éƒ¨åˆ†é“¾æ¥: video/BV1zsnBzGEzC
        - éƒ¨åˆ†é“¾æ¥: com/video/BV1zsnBzGEzC
        - å¸¦å‚æ•°é“¾æ¥: BV1zsnBzGEzC?spm_id_from=333.788
        - CID: ç›´æ¥ä½¿ç”¨CID
        """
        if not input_str:
            return None
        
        input_str = input_str.strip()
        
        # 1. æ£€æŸ¥æ˜¯å¦æ˜¯çº¯BVå·æ ¼å¼
        if input_str.startswith('BV') and len(input_str) >= 10:
            # å¤„ç†å¸¦å‚æ•°çš„BVå·ï¼Œå¦‚: BV1zsnBzGEzC?spm_id_from=333.788
            if '?' in input_str:
                return input_str.split('?')[0]
            return input_str
        
        # 2. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»å„ç§æ ¼å¼ä¸­æå–BVå·
        import re
        pattern = r'BV[a-zA-Z0-9]{10,}'
        match = re.search(pattern, input_str)
        if match:
            bvid = match.group()
            # éªŒè¯æå–çš„BVå·æ˜¯å¦æœ‰æ•ˆ
            if bvid.startswith('BV') and len(bvid) >= 10:
                return bvid
        
        # 3. å¦‚æœæ˜¯çº¯æ•°å­—ï¼Œå¯èƒ½æ˜¯CIDï¼Œè¿”å›Noneè®©è°ƒç”¨æ–¹å¤„ç†
        if input_str.isdigit():
            return None
        
        return None

    async def download_single_video_direct(self, session: httpx.AsyncClient):
        """
        ç›´æ¥ä¸‹è½½å•ä¸ªè§†é¢‘
        æ”¯æŒè¾“å…¥: BVå·ã€é“¾æ¥ã€CID
        """
        global interrupted
        
        print("\nç›´æ¥ä¸‹è½½è§†é¢‘")
        print("æ”¯æŒè¾“å…¥æ ¼å¼:")
        print("  - BVå·: BV1zsnBzGEzC")
        print("  - å®Œæ•´é“¾æ¥: https://www.bilibili.com/video/BV1zsnBzGEzC/")
        print("  - éƒ¨åˆ†é“¾æ¥: com/video/BV1zsnBzGEzC")
        print("  - å¸¦å‚æ•°é“¾æ¥: BV1zsnBzGEzC?spm_id_from=333.788")
        print("  - CID: ç›´æ¥è¾“å…¥CID")
        print("è¯´æ˜: åªè¦åŒ…å«å®Œæ•´çš„BVå·å³å¯è¯†åˆ«")
        
        while True:
            print("\nè¯·è¾“å…¥è§†é¢‘æ ‡è¯† (è¾“å…¥'q'è¿”å›ä¸»èœå•): ", end="")
            video_input = input().strip()
            
            if video_input.lower() == 'q':
                return
            
            if not video_input:
                print("è¾“å…¥ä¸èƒ½ä¸ºç©º")
                continue
            
            # æå–BVå·
            bvid = self.extract_bvid_from_input(video_input)
            
            if bvid:
                # ä½¿ç”¨BVå·ä¸‹è½½
                print(f"æ£€æµ‹åˆ°BVå·: {bvid}")
                await self.download_by_bvid(session, bvid)
                break
            elif video_input.isdigit():
                # ä½¿ç”¨CIDä¸‹è½½
                cid = int(video_input)
                print(f"ä½¿ç”¨CID: {cid}")
                await self.download_by_cid(session, cid)
                break
            else:
                print("æ— æ³•è¯†åˆ«è¾“å…¥æ ¼å¼ï¼Œè¯·é‡æ–°è¾“å…¥")

    async def download_by_bvid(self, session: httpx.AsyncClient, bvid: str):
        """é€šè¿‡BVå·ä¸‹è½½è§†é¢‘"""
        global interrupted
        
        # è·å–è§†é¢‘ä¿¡æ¯
        video_info = await self.get_video_info(session, bvid)
        if not video_info:
            print(f"æ— æ³•è·å–è§†é¢‘ä¿¡æ¯: {bvid}")
            return
        
        title = video_info.get("title", "æœªçŸ¥æ ‡é¢˜")
        print(f"è§†é¢‘æ ‡é¢˜: {title}")
        
        # è·å–æ¸…æ™°åº¦
        quality_options = list(QUALITY_MAP.keys())
        print("\nå¯ç”¨æ¸…æ™°åº¦:")
        for i, q in enumerate(quality_options, 1):
            print(f"{i}. {q}")
        
        default_quality_index = quality_options.index('1080P') + 1 if '1080P' in quality_options else 4
        print(f"è¯·é€‰æ‹©æ¸…æ™°åº¦ (1-{len(quality_options)}, é»˜è®¤{default_quality_index}): ", end="")
        quality_choice = input().strip()
        
        if not quality_choice:
            quality_choice = str(default_quality_index)
        
        if quality_choice.isdigit():
            choice_index = int(quality_choice) - 1
            if 0 <= choice_index < len(quality_options):
                quality = quality_options[choice_index]
            else:
                print(f"è¾“å…¥è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨é»˜è®¤{quality_options[default_quality_index-1]}")
                quality = quality_options[default_quality_index-1]
        else:
            print(f"æ— æ•ˆè¾“å…¥ï¼Œä½¿ç”¨é»˜è®¤{quality_options[default_quality_index-1]}")
            quality = quality_options[default_quality_index-1]
        
        # éä¼šå‘˜æ¸…æ™°åº¦è°ƒæ•´
        if not self.is_member and QUALITY_MAP.get(quality, 0) > NON_MEMBER_MAX_QUALITY:
            print(f"æ™®é€šè´¦å·æœ€é«˜æ”¯æŒ1080Pï¼Œå·²è‡ªåŠ¨è°ƒæ•´ä¸º1080P")
            quality = "1080P"
        
        # è·å–è¾“å‡ºç›®å½•
        print("è¯·è¾“å…¥ä¸‹è½½è·¯å¾„ (é»˜è®¤./direct_download): ", end="")
        output_dir = input().strip() or "./direct_download"
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # è·å–æ¸…æ™°åº¦ä»£ç 
        quality_code = QUALITY_MAP.get(quality, 80)
        
        # ä¸‹è½½è§†é¢‘
        success = await self.download_single_video(
            session, bvid, title, output_dir, quality_code, False
        )
        
        if success:
            print(f"è§†é¢‘ä¸‹è½½å®Œæˆ: {title}")
        else:
            print(f"è§†é¢‘ä¸‹è½½å¤±è´¥: {title}")

    async def download_by_cid(self, session: httpx.AsyncClient, cid: int):
        """é€šè¿‡CIDä¸‹è½½è§†é¢‘"""
        global interrupted
        
        print("é€šè¿‡CIDä¸‹è½½åŠŸèƒ½éœ€è¦BVå·ä¿¡æ¯ï¼Œè¯·å…ˆæä¾›BVå·")
        print("è¯·è¾“å…¥BVå·: ", end="")
        bvid = input().strip()
        
        if not bvid.startswith('BV'):
            print("æ— æ•ˆçš„BVå·æ ¼å¼")
            return
        
        # è·å–è§†é¢‘ä¿¡æ¯éªŒè¯CID
        video_info = await self.get_video_info(session, bvid)
        if not video_info:
            print(f"æ— æ³•è·å–è§†é¢‘ä¿¡æ¯: {bvid}")
            return
        
        # æ£€æŸ¥CIDæ˜¯å¦æœ‰æ•ˆ
        pages = await self.get_video_pages(session, bvid)
        valid_cids = [page["cid"] for page in pages]
        
        if cid not in valid_cids:
            print(f"CID {cid} åœ¨è§†é¢‘ {bvid} ä¸­ä¸å­˜åœ¨")
            print(f"æœ‰æ•ˆçš„CID: {valid_cids}")
            return
        
        # æ‰¾åˆ°å¯¹åº”çš„åˆ†Pæ ‡é¢˜
        part_title = "æœªçŸ¥åˆ†P"
        for page in pages:
            if page["cid"] == cid:
                part_title = page.get("part", "æœªçŸ¥åˆ†P")
                break
        
        print(f"æ‰¾åˆ°åˆ†P: {part_title} (CID: {cid})")
        
        # è·å–æ¸…æ™°åº¦
        quality_options = list(QUALITY_MAP.keys())
        print("\nå¯ç”¨æ¸…æ™°åº¦:")
        for i, q in enumerate(quality_options, 1):
            print(f"{i}. {q}")
        
        default_quality_index = quality_options.index('1080P') + 1 if '1080P' in quality_options else 4
        print(f"è¯·é€‰æ‹©æ¸…æ™°åº¦ (1-{len(quality_options)}, é»˜è®¤{default_quality_index}): ", end="")
        quality_choice = input().strip()
        
        if not quality_choice:
            quality_choice = str(default_quality_index)
        
        if quality_choice.isdigit():
            choice_index = int(quality_choice) - 1
            if 0 <= choice_index < len(quality_options):
                quality = quality_options[choice_index]
            else:
                print(f"è¾“å…¥è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨é»˜è®¤{quality_options[default_quality_index-1]}")
                quality = quality_options[default_quality_index-1]
        else:
            print(f"æ— æ•ˆè¾“å…¥ï¼Œä½¿ç”¨é»˜è®¤{quality_options[default_quality_index-1]}")
            quality = quality_options[default_quality_index-1]
        
        # éä¼šå‘˜æ¸…æ™°åº¦è°ƒæ•´
        if not self.is_member and QUALITY_MAP.get(quality, 0) > NON_MEMBER_MAX_QUALITY:
            print(f"æ™®é€šè´¦å·æœ€é«˜æ”¯æŒ1080Pï¼Œå·²è‡ªåŠ¨è°ƒæ•´ä¸º1080P")
            quality = "1080P"
        
        # è·å–è¾“å‡ºç›®å½•
        print("è¯·è¾“å…¥ä¸‹è½½è·¯å¾„ (é»˜è®¤./direct_download): ", end="")
        output_dir = input().strip() or "./direct_download"
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # è·å–æ¸…æ™°åº¦ä»£ç 
        quality_code = QUALITY_MAP.get(quality, 80)
        
        # ä¸‹è½½æŒ‡å®šåˆ†P
        success = await self.download_single_video_by_cid(
            session, bvid, cid, part_title, output_dir, quality_code
        )
        
        if success:
            print(f"åˆ†Pä¸‹è½½å®Œæˆ: {part_title}")
        else:
            print(f"åˆ†Pä¸‹è½½å¤±è´¥: {part_title}")

    async def download_single_video_by_cid(self, session: httpx.AsyncClient, bvid: str, cid: int, title: str, output_path: str, quality: int) -> bool:
        """é€šè¿‡CIDä¸‹è½½å•ä¸ªåˆ†Pè§†é¢‘"""
        global interrupted
        
        try:
            # ä¸ºåˆ†Pç”Ÿæˆç‹¬ç«‹çš„æ–‡ä»¶å
            safe_title = sanitize_filename(title)
            safe_title = shorten_filename(safe_title)
            file_path = os.path.join(output_path, f"{safe_title}_{bvid}.mp4")
            
            # è·å–åª’ä½“URL
            media_info = await self.get_video_url(session, bvid, cid, quality)
            if not media_info:
                print(f"è·³è¿‡åˆ†P: {title} ({bvid}) - æ— æ³•è·å–ä¸‹è½½é“¾æ¥")
                return False
            
            # æ„å»ºè¯·æ±‚å¤´
            headers = {
                "User-Agent": HEADERS["User-Agent"],
                "Referer": "https://www.bilibili.com",
                "Cookie": "; ".join([f"{k}={v}" for k, v in session.cookies.items()])
            }
            
            # ä¸‹è½½è§†é¢‘æ–‡ä»¶
            video_url = media_info["video_url"]
            video_file = os.path.join(output_path, f"{safe_title}_{bvid}_video.tmp")
            
            # ä¸‹è½½è§†é¢‘
            video_success = await self.download_file(
                video_url, video_file, title, "è§†é¢‘", headers
            )
            
            if not video_success:
                return False
            
            # ä¸‹è½½éŸ³é¢‘æ–‡ä»¶ï¼ˆå¦‚æœæ˜¯DASHæ ¼å¼ï¼‰
            audio_file = None
            audio_success = True
            
            if media_info["audio_url"] and self.ffmpeg_available:
                audio_url = media_info["audio_url"]
                audio_file = os.path.join(output_path, f"{safe_title}_{bvid}_audio.tmp")
                
                # ä¸‹è½½éŸ³é¢‘
                audio_success = await self.download_file(
                    audio_url, audio_file, title, "éŸ³é¢‘", headers
                )
            
            # å¤„ç†éŸ³é¢‘ä¸‹è½½å¤±è´¥æƒ…å†µ
            if not audio_success:
                if os.path.exists(video_file):
                    try:
                        os.rename(video_file, file_path)
                        print(f"éŸ³é¢‘ä¸‹è½½å¤±è´¥ï¼Œå·²ä¿å­˜è§†é¢‘æ–‡ä»¶: {title}")
                        return True
                    except Exception as e:
                        print(f"é‡å‘½åè§†é¢‘æ–‡ä»¶å¤±è´¥: {title} - {str(e)}")
                return False
            
            # å¤„ç†éŸ³è§†é¢‘åˆå¹¶
            if audio_file and os.path.exists(audio_file):
                # åŠ å…¥åˆå¹¶é˜Ÿåˆ—
                if self.queue_merge_task(video_file, audio_file, file_path, title, bvid):
                    return True
            else:
                # éDASHæ ¼å¼ï¼Œç›´æ¥é‡å‘½åè§†é¢‘æ–‡ä»¶
                if os.path.exists(video_file):
                    try:
                        os.rename(video_file, file_path)
                        print(f"ä¸‹è½½å®Œæˆ: {title} ({bvid})")
                        return True
                    except Exception as e:
                        print(f"é‡å‘½åè§†é¢‘æ–‡ä»¶å¤±è´¥: {title} - {str(e)}")
            
            return False
            
        except Exception as e:
            print(f"ä¸‹è½½å¤±è´¥: {title} ({bvid}) - {str(e)}")
            return False

# ========================
# ç¨‹åºå…¥å£
# ========================

if __name__ == "__main__":
    downloader = None
    try:
        # åˆ›å»ºä¸‹è½½å™¨å®ä¾‹å¹¶è¿è¡Œ
        downloader = BiliFavDownloader()
        asyncio.run(downloader.run())
    except Exception as e:
        print(f"ç¨‹åºå‘ç”Ÿé”™è¯¯: {str(e)}")
    finally:
        # ç¡®ä¿åˆå¹¶çº¿ç¨‹è¢«åœæ­¢
        if downloader and hasattr(downloader, 'stop_merge_thread'):
            downloader.stop_merge_thread()
