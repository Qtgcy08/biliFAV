import asyncio
import aiohttp
import toml
import qrcode
import sqlite3
import time
import random
import json
import os
import signal
import sys
import io
import threading
from pathlib import Path
from typing import Optional, Dict, List, Tuple, Any, Callable
import httpx
import concurrent.futures
import re
import logging
from datetime import datetime, timedelta
from tqdm import tqdm
import ffmpeg
import shutil
import subprocess

# è®¾ç½®ç³»ç»Ÿé»˜è®¤ç¼–ç 
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# å‡å°‘HTTPXçš„è¯¦ç»†æ—¥å¿—
httpx_logger = logging.getLogger("httpx")
httpx_logger.setLevel(logging.WARNING)

# æ§åˆ¶å°å¤„ç†å™¨
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.WARNING)
console_formatter = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")
console_handler.setFormatter(console_formatter)

logger.addHandler(console_handler)
logger.propagate = False

# é…ç½®æ–‡ä»¶è·¯å¾„
TOKEN_FILE = "bili_token.toml"
DB_FILE = ".get_my_favourite.sqlite"

# è¯·æ±‚å¤´é…ç½®
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Referer": "https://www.bilibili.com"
}

# æ‰©å±•æ¸…æ™°åº¦æ˜ å°„è¡¨
QUALITY_MAP = {
    "4K": 120,
    "1080P60": 112,
    "1080P+": 116,
    "1080P": 80,
    "720P60": 74,
    "720P": 64,
    "480P": 32,
    "360P": 16,
    "æœ€ä½": 6
}

# æ¸…æ™°åº¦ä»£ç åˆ°æè¿°çš„æ˜ å°„
QUALITY_CODE_TO_DESC = {
    120: "4K",
    112: "1080P60",
    116: "1080P+",
    80: "1080P",
    74: "720P60",
    64: "720P",
    32: "480P",
    16: "360P",
    6: "æœ€ä½"
}

# éå¤§ä¼šå‘˜æœ€é«˜åˆ†è¾¨ç‡
NON_MEMBER_MAX_QUALITY = 80

# å…¨å±€ä¸­æ–­æ ‡å¿—
interrupted = False
overwrite_all = False
skip_existing = False

def signal_handler(sig, frame):
    """å¤„ç†ä¸­æ–­ä¿¡å·"""
    global interrupted
    interrupted = True
    logger.warning("æ£€æµ‹åˆ°ä¸­æ–­ï¼Œæ­£åœ¨é€€å‡º...")
    print("\nç¨‹åºè¢«ä¸­æ–­ï¼Œæ­£åœ¨æ¸…ç†èµ„æº...")

signal.signal(signal.SIGINT, signal_handler)

def sanitize_filename(filename: str) -> str:
    """æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦ï¼Œä½†ä¿ç•™emoji"""
    return re.sub(r'[<>:"/\\|?*]', '', filename)

def shorten_filename(filename: str, max_length: int = 180) -> str:
    """ç¼©çŸ­æ–‡ä»¶åä»¥é˜²æ­¢è·¯å¾„è¿‡é•¿"""
    if len(filename) <= max_length:
        return filename
    
    # ä¿ç•™æ‰©å±•å
    name, ext = os.path.splitext(filename)
    # æˆªæ–­æ–‡ä»¶åä¸»ä½“
    name = name[:max_length - len(ext) - 10]  # ä¿ç•™10ä¸ªå­—ç¬¦ç»™éšæœºåç¼€
    # æ·»åŠ éšæœºåç¼€é˜²æ­¢å†²çª
    suffix = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz1234567890', k=8))
    return f"{name}_{suffix}{ext}"

class BiliFavDownloader:
    def __init__(self):
        self.cookies = {}
        self.token_data = {}
        self.all_data = []
        self.db_exists = Path(DB_FILE).exists()
        self.is_member = False
        self.qr_file = None  # é»˜è®¤ä¸ºNoneï¼Œä¸ä¿å­˜æ–‡ä»¶
        self.ffmpeg_available = False
        self.ffmpeg_version = "æœªçŸ¥"
        self.ffmpeg_path = None
        self.merge_queue = []
        self.merge_lock = threading.Lock()
        self.merge_thread = None
        self.merge_running = True
        self.last_updated = None
        self.current_update_time = None
        self.first_run = not self.db_exists  # æ ‡è®°æ˜¯å¦æ˜¯é¦–æ¬¡è¿è¡Œ
    
    async def initialize(self):
        """åˆå§‹åŒ–ä¸‹è½½å™¨"""
        global interrupted
        
        self.check_ffmpeg()
        
        # è·å–tokenæˆ–äºŒç»´ç ç™»å½•
        self.token_data = await self.check_token()
        if not self.token_data:
            print("æœªæ£€æµ‹åˆ°ç™»å½•ä¿¡æ¯ï¼Œéœ€è¦ç™»å½•...")
            self.token_data = await self.qr_login()
            if interrupted:  # æ£€æŸ¥æ˜¯å¦åœ¨ç™»å½•è¿‡ç¨‹ä¸­è¢«ä¸­æ–­
                print("ç™»å½•è¿‡ç¨‹è¢«ä¸­æ–­")
                return False
            if self.token_data:
                self.save_token(self.token_data)
            else:
                print("ç™»å½•å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
                return False
        
        # åˆ›å»ºå¸¦Cookieçš„ä¼šè¯
        if self.token_data:
            self.cookies = self.token_data["cookies"]
        
        # æ£€æŸ¥ä¼šå‘˜çŠ¶æ€ï¼ˆåªæœ‰åœ¨æœ‰cookiesçš„æƒ…å†µä¸‹ï¼‰
        if self.cookies:
            try:
                # æ·»åŠ è¶…æ—¶å’Œä¸­æ–­æ£€æŸ¥
                if interrupted: 
                    return False
                    
                print("æ­£åœ¨æ£€æŸ¥ä¼šå‘˜çŠ¶æ€...")
                self.is_member = await self.check_member_status()
                if self.is_member:
                    print("æ£€æµ‹åˆ°å¤§ä¼šå‘˜è´¦å·ï¼Œå¯ä¸‹è½½é«˜åˆ†è¾¨ç‡è§†é¢‘")
                else:
                    print("æ™®é€šè´¦å·ï¼Œæœ€é«˜å¯ä¸‹è½½1080Påˆ†è¾¨ç‡")
            except Exception as e:
                print(f"æ£€æŸ¥ä¼šå‘˜çŠ¶æ€å¤±è´¥: {str(e)}")
                print("é»˜è®¤ä½¿ç”¨æ™®é€šè´¦å·æ¨¡å¼")
                self.is_member = False
        
        # å¯åŠ¨åˆå¹¶çº¿ç¨‹
        self.start_merge_thread()
        
        # è·å–æ•°æ®åº“æœ€åæ›´æ–°æ—¶é—´
        self.get_last_updated_time()
        
        return True
    
    def get_last_updated_time(self):
        """è·å–æ•°æ®åº“æœ€åæ›´æ–°æ—¶é—´"""
        if not self.db_exists:
            self.last_updated = None
            return
        
        try:
            conn = sqlite3.connect(DB_FILE)
            c = conn.cursor()
            
            c.execute("PRAGMA table_info(favorites)")
            columns = [col[1] for col in c.fetchall()]
            if "last_updated" not in columns:
                self.last_updated = None
                return
            
            c.execute("SELECT MAX(last_updated) FROM favorites")
            result = c.fetchone()
            if result and result[0]:
                self.last_updated = datetime.fromisoformat(result[0])
            else:
                self.last_updated = None
        except Exception as e:
            print(f"è·å–æ•°æ®åº“æœ€åæ›´æ–°æ—¶é—´å¤±è´¥: {str(e)}")
            self.last_updated = None
        finally:
            if conn:
                conn.close()
    
    def check_ffmpeg(self):
        """æ£€æŸ¥ç³»ç»Ÿä¸Šçš„FFmpegæ˜¯å¦å¯ç”¨"""
        try:
            result = subprocess.run(
                ["ffmpeg", "-version"], 
                capture_output=True, 
                text=True,
                encoding='utf-8',
                errors='ignore',
                creationflags=subprocess.CREATE_NO_WINDOW
            )
            if result.returncode == 0:
                version_line = result.stdout.split('\n')[0]
                parts = version_line.split(' ')
                version = parts[2] if len(parts) > 2 else "æœªçŸ¥"
                self.ffmpeg_version = version
                self.ffmpeg_available = True
                self.ffmpeg_path = shutil.which("ffmpeg")
                print(f"FFmpegæ£€æµ‹æˆåŠŸ (ç‰ˆæœ¬: {self.ffmpeg_version}, è·¯å¾„: {self.ffmpeg_path})")
                return
        
        except Exception as e:
            print(f"FFmpegæ£€æµ‹å¼‚å¸¸: {str(e)}")
        
        ffmpeg_path = shutil.which("ffmpeg")
        if ffmpeg_path:
            self.ffmpeg_path = ffmpeg_path
            self.ffmpeg_available = True
            print(f"FFmpegæ£€æµ‹æˆåŠŸ (è·¯å¾„: {ffmpeg_path})")
        else:
            print("è­¦å‘Š: æœªæ£€æµ‹åˆ°FFmpegï¼ŒDASHæ ¼å¼è§†é¢‘å°†æ— æ³•åˆå¹¶éŸ³é¢‘")
            print("   è¯·å®‰è£…FFmpegå¹¶æ·»åŠ åˆ°ç³»ç»ŸPATHï¼šhttps://ffmpeg.org/download.html")
            self.ffmpeg_available = False
    
    def start_merge_thread(self):
        """å¯åŠ¨åˆå¹¶çº¿ç¨‹"""
        if not self.ffmpeg_available:
            print("åˆå¹¶çº¿ç¨‹æœªå¯åŠ¨ï¼Œå› ä¸ºFFmpegä¸å¯ç”¨")
            return
        
        self.merge_running = True
        self.merge_thread = threading.Thread(target=self._merge_worker, daemon=True)
        self.merge_thread.start()
        print("åå°åˆå¹¶çº¿ç¨‹å·²å¯åŠ¨")
    
    def stop_merge_thread(self):
        """åœæ­¢åˆå¹¶çº¿ç¨‹"""
        if self.merge_thread and self.merge_thread.is_alive():
            self.merge_running = False
            self.merge_thread.join(timeout=5.0)
            print("åå°åˆå¹¶çº¿ç¨‹å·²åœæ­¢")
    
    def _merge_worker(self):
        """åˆå¹¶å·¥ä½œçº¿ç¨‹"""
        print(f"\nåˆå¹¶çº¿ç¨‹å¯åŠ¨ (FFmpegè·¯å¾„: {self.ffmpeg_path})")
        
        while self.merge_running or self.merge_queue:
            if interrupted:
                break
                
            if not self.merge_queue:
                time.sleep(0.5)
                continue
            
            with self.merge_lock:
                task = self.merge_queue.pop(0) if self.merge_queue else None
            
            if not task:
                continue
                
            video_file, audio_file, output_file, title, bvid = task
            
            try:
                print(f"\nå¼€å§‹åˆå¹¶: {title} ({bvid}) [ä½¿ç”¨FFmpeg]")
                
                ffmpeg_cmd = [
                    self.ffmpeg_path,
                    '-i', video_file,
                    '-i', audio_file,
                    '-c', 'copy',
                    '-map', '0:v:0',
                    '-map', '1:a:0',
                    '-y',
                    output_file
                ]
                
                process = subprocess.run(
                    ffmpeg_cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    encoding='utf-8',
                    errors='ignore',
                    creationflags=subprocess.CREATE_NO_WINDOW
                )
                
                if process.returncode != 0:
                    error_msg = process.stderr if process.stderr else "æ— é”™è¯¯ä¿¡æ¯"
                    raise Exception(f"FFmpegåˆå¹¶å¤±è´¥ (è¿”å›ç  {process.returncode}): {error_msg}")
                
                if os.path.exists(video_file):
                    os.remove(video_file)
                if os.path.exists(audio_file):
                    os.remove(audio_file)
                
                print(f"åˆå¹¶å®Œæˆ: {title} ({bvid})\n")
                
            except Exception as e:
                print(f"åˆå¹¶è§†é¢‘å¤±è´¥: {title} ({bvid}) - {str(e)}")
                if os.path.exists(video_file):
                    try:
                        os.rename(video_file, output_file)
                        print(f"å·²ä¿å­˜è§†é¢‘æ–‡ä»¶ï¼ˆæ— éŸ³é¢‘ï¼‰: {title}")
                    except Exception:
                        pass
    
    def queue_merge_task(self, video_file: str, audio_file: str, output_file: str, title: str, bvid: str):
        """å°†åˆå¹¶ä»»åŠ¡æ·»åŠ åˆ°é˜Ÿåˆ—"""
        if not self.ffmpeg_available:
            print(f"æ— æ³•åˆå¹¶: {title} ({bvid}) - FFmpegä¸å¯ç”¨")
            return False
        
        with self.merge_lock:
            self.merge_queue.append((video_file, audio_file, output_file, title, bvid))
        
        # ä¿®å¤ï¼šåˆå¹¶é˜Ÿåˆ—æ¶ˆæ¯æ¢è¡Œæ˜¾ç¤º
        print(f"\nå·²åŠ å…¥åˆå¹¶é˜Ÿåˆ—: {title} (é˜Ÿåˆ—é•¿åº¦: {len(self.merge_queue)})")
        return True
    
    def save_token(self, token_data: Dict):
        """ä¿å­˜tokenåˆ°æ–‡ä»¶"""
        try:
            with open(TOKEN_FILE, "w") as f:
                toml.dump(token_data, f)
            print(f"ç™»å½•ä¿¡æ¯å·²ä¿å­˜\n")
        except Exception as e:
            print(f"ä¿å­˜ç™»å½•ä¿¡æ¯å¤±è´¥: {str(e)}")
    
    async def check_member_status(self) -> bool:
        """æ£€æŸ¥ç”¨æˆ·å¤§ä¼šå‘˜çŠ¶æ€"""
        try:
            async with httpx.AsyncClient(headers=HEADERS, cookies=self.cookies, timeout=10.0) as client:
                resp = await client.get("https://api.bilibili.com/x/web-interface/nav")
                resp.raise_for_status()
                data = resp.json()
                if data.get("code") == 0:
                    return data["data"].get("vipStatus", 0) == 1
        except Exception as e:
            print(f"æ£€æŸ¥ä¼šå‘˜çŠ¶æ€å¤±è´¥: {str(e)}")
        return False

    def get_token(self) -> Dict:
        return self.token_data
    
    async def check_token(self) -> Optional[Dict]:
        if Path(TOKEN_FILE).exists():
            try:
                return toml.load(TOKEN_FILE)
            except Exception as e:
                print(f"è¯»å–ç™»å½•ä¿¡æ¯å¤±è´¥: {str(e)}")
                # åˆ é™¤æ— æ•ˆçš„tokenæ–‡ä»¶
                try:
                    os.remove(TOKEN_FILE)
                    print("å·²åˆ é™¤æ— æ•ˆçš„ç™»å½•ä¿¡æ¯")
                except:
                    pass
        return None

    async def qr_login(self, qr_output: str = None) -> Dict:
        """äºŒç»´ç ç™»å½•ï¼Œé»˜è®¤ä¸ä¿å­˜æ–‡ä»¶"""
        print("è¯·æ‰“å¼€å“”å“©å“”å“©APPæ‰«æäºŒç»´ç ç™»å½•...")
        
        # å¦‚æœæŒ‡å®šäº†è¾“å‡ºæ–‡ä»¶ï¼Œåˆ™ä¿å­˜äºŒç»´ç 
        if qr_output:
            self.qr_file = qr_output
            print(f"äºŒç»´ç å°†ä¿å­˜åˆ°: {qr_output}")
        else:
            self.qr_file = None
        
        try:
            async with httpx.AsyncClient(headers=HEADERS, timeout=30.0) as client:
                qr_resp = await client.get("https://passport.bilibili.com/x/passport-login/web/qrcode/generate")
                qr_resp.raise_for_status()
                qr_data = qr_resp.json()
                
                if qr_data.get("code") != 0:
                    print(f"è·å–äºŒç»´ç å¤±è´¥: {qr_data.get('message')}")
                    return None
                
                qr_url = qr_data["data"]["url"]
                qrcode_key = qr_data["data"]["qrcode_key"]
                
                # åˆ›å»ºé«˜åˆ†è¾¨ç‡äºŒç»´ç  (600Ã—600)
                qr = qrcode.QRCode(
                    version=1,
                    error_correction=qrcode.constants.ERROR_CORRECT_L,
                    box_size=15,  # å¢å¤§box_sizeä»¥æé«˜åˆ†è¾¨ç‡
                    border=2,
                )
                qr.add_data(qr_url)
                qr.make(fit=True)
                
                # åœ¨ç»ˆç«¯æ‰“å°äºŒç»´ç 
                print("\nç»ˆç«¯äºŒç»´ç é¢„è§ˆ:")
                qr.print_ascii(invert=True)  # ä½¿ç”¨ASCIIå­—ç¬¦æ‰“å°äºŒç»´ç 
                
                # å¦‚æœéœ€è¦ä¿å­˜æ–‡ä»¶
                if self.qr_file:
                    img = qr.make_image(fill_color="black", back_color="white")
                    # è°ƒæ•´å›¾åƒå¤§å°ä¸º600Ã—600
                    img = img.resize((600, 600))
                    img.save(self.qr_file)
                    print(f"\näºŒç»´ç å·²ä¿å­˜ä¸º: {self.qr_file}")
                
                print("\nè¯·ä½¿ç”¨å“”å“©å“”å“©APPæ‰«ç ç™»å½•ï¼ˆäºŒç»´ç æœ‰æ•ˆæœŸä¸º180ç§’ï¼‰")
                print("æŒ‰Ctrl+Cå¯å–æ¶ˆç™»å½•")
                
                # ä½¿ç”¨æ›´ç»†ç²’åº¦çš„å¾ªç¯ä»¥ä¾¿æ›´å¿«å“åº”ä¸­æ–­
                for i in range(180):  # 180ç§’ï¼Œæ¯ç§’æ£€æŸ¥ä¸€æ¬¡
                    # æ¯æ¬¡å¾ªç¯å¼€å§‹æ£€æŸ¥ä¸­æ–­
                    if interrupted:
                        print("\nç™»å½•è¿‡ç¨‹è¢«ä¸­æ–­")
                        return None
                    
                    # æ¯ç§’æ‰“å°ä¸€æ¬¡è¿›åº¦
                    print(f"\rç­‰å¾…æ‰«ç ç¡®è®¤... [{i}/180ç§’]", end="", flush=True)
                    
                    try:
                        check_resp = await client.get(
                            "https://passport.bilibili.com/x/passport-login/web/qrcode/poll",
                            params={"qrcode_key": qrcode_key},
                            timeout=5.0
                        )
                        check_resp.raise_for_status()
                        check_data = check_resp.json()
                    except httpx.TimeoutException:
                        # è¶…æ—¶ç»§ç»­å°è¯•
                        await asyncio.sleep(1)
                        continue
                    except Exception as e:
                        print(f"\næ£€æŸ¥ç™»å½•çŠ¶æ€å¤±è´¥: {str(e)}")
                        await asyncio.sleep(1)
                        continue
                    
                    if check_data.get("data", {}).get("code") == 86038:
                        print("\näºŒç»´ç å·²è¿‡æœŸï¼Œè¯·é‡æ–°è¿è¡Œç¨‹åºè·å–æ–°äºŒç»´ç ")
                        return None
                    elif check_data.get("data", {}).get("code") == 86039:
                        # ç­‰å¾…1ç§’åç»§ç»­
                        await asyncio.sleep(1)
                        continue
                    elif check_data.get("data", {}).get("code") == 0:
                        cookies = self.parse_cookies(str(check_resp.headers.get("set-cookie", "")))
                        if not cookies:
                            print("\nè·å–ç™»å½•Cookieå¤±è´¥")
                            return None
                        
                        token_info = {
                            "cookies": cookies,
                            "timestamp": int(time.time())
                        }
                        print("\nç™»å½•æˆåŠŸï¼")
                        return token_info
                    
                    # ç­‰å¾…1ç§’
                    await asyncio.sleep(1)
                
                print("\nç™»å½•è¶…æ—¶ï¼Œè¯·é‡è¯•")
                return None
        except Exception as e:
            print(f"\nç™»å½•å‡ºé”™: {str(e)}")
            return None
    
    def parse_cookies(self, cookie_header: str) -> Dict:
        cookies = {}
        if not cookie_header:
            return cookies
        
        for item in cookie_header.split(","):
            item = item.strip()
            if "SESSDATA=" in item:
                cookies["SESSDATA"] = item.split("SESSDATA=")[1].split(";")[0]
            elif "bili_jct=" in item:
                cookies["bili_jct"] = item.split("bili_jct=")[1].split(";")[0]
            elif "DedeUserID=" in item:
                cookies["DedeUserID"] = item.split("DedeUserID=")[1].split(";")[0]
        return cookies

    async def get_favorites(self, session: httpx.AsyncClient) -> List[Dict]:
        try:
            print("æ­£åœ¨è·å–æ”¶è—å¤¹åˆ—è¡¨...")
            resp = await session.get(
                "https://api.bilibili.com/x/v3/fav/folder/created/list-all",
                params={"up_mid": session.cookies.get("DedeUserID")},
                timeout=30.0
            )
            resp.raise_for_status()
            data = resp.json()
            if data.get("code") != 0:
                print(f"è·å–æ”¶è—å¤¹åˆ—è¡¨å¤±è´¥: {data.get('message')}")
                return []
            return data["data"]["list"]
        except Exception as e:
            print(f"è·å–æ”¶è—å¤¹åˆ—è¡¨å¤±è´¥: {str(e)}")
            return []
    
    async def get_favorite_detail(self, session: httpx.AsyncClient, media_id: int, media_count: int) -> List[Dict]:
        global interrupted
        all_items = []
        page = 1
        page_size = 20
        
        try:
            print(f"å¼€å§‹è·å–æ”¶è—å¤¹å†…å®¹ï¼Œå…±çº¦{media_count}é¡¹...")
            
            # ä½¿ç”¨tqdmè¿›åº¦æ¡å®ç°åŠ¨æ€åˆ·æ–°
            pbar = tqdm(total=media_count, desc=f"æ”¶è—å¤¹ID {media_id}", unit="é¡¹")
            count = 0
            
            while not interrupted:
                # éšæœºå»¶è¿Ÿé˜²æ­¢è¯·æ±‚è¿‡å¿«
                delay = random.uniform(0.1, 0.8)
                await asyncio.sleep(delay)
                
                try:
                    resp = await session.get(
                        "https://api.bilibili.com/x/v3/fav/resource/list",
                        params={
                            "media_id": media_id,
                            "ps": page_size,
                            "pn": page,
                            "platform": "web"
                        },
                        timeout=30.0
                    )
                    resp.raise_for_status()
                    data = resp.json()
                    
                    if data.get("code") != 0:
                        if page == 1:
                            print(f"è·å–æ”¶è—å¤¹è¯¦æƒ…å¤±è´¥: {data.get('message')}")
                        page += 1
                        if page > 50:
                            break
                        continue
                    
                    items = data["data"].get("medias", [])
                    all_items.extend(items)
                    count = len(all_items)
                    
                    # æ›´æ–°è¿›åº¦æ¡
                    pbar.update(len(items))
                    
                    has_more = data["data"].get("has_more", 0) == 1
                    if not has_more or len(items) < page_size:
                        break
                        
                    page += 1
                    if page > 50:
                        break
                except Exception as e:
                    print(f"è·å–æ”¶è—å¤¹è¯¦æƒ…å¤±è´¥: {str(e)}")
                    page += 1
                    if page > 50:
                        break
            
            pbar.close()
            print(f"è·å–å®Œæˆ: {count}/{media_count} é¡¹")
            return all_items
        except Exception as e:
            print(f"\nè·å–æ”¶è—å¤¹è¯¦æƒ…å¤±è´¥: {str(e)}")
            return all_items

    def upgrade_database(self):
        """å‡çº§æ•°æ®åº“ç»“æ„"""
        if not self.db_exists:
            # é¦–æ¬¡è¿è¡Œæ—¶åˆ›å»ºæ•°æ®åº“
            print(f"\né¦–æ¬¡è¿è¡Œï¼Œåˆ›å»ºæ•°æ®åº“...")
            try:
                conn = sqlite3.connect(DB_FILE)
                c = conn.cursor()
                
                # åˆ›å»ºæ”¶è—å¤¹è¡¨
                c.execute("""
                CREATE TABLE IF NOT EXISTS favorites (
                    id INTEGER PRIMARY KEY,
                    title TEXT,
                    media_id INTEGER,
                    count INTEGER,
                    last_updated TEXT
                )
                """)
                
                # åˆ›å»ºæ”¶è—é¡¹è¡¨
                c.execute("""
                CREATE TABLE IF NOT EXISTS favorite_items (
                    id TEXT PRIMARY KEY,
                    favorite_id INTEGER,
                    title TEXT,
                    bvid TEXT,
                    owner_name TEXT,
                    FOREIGN KEY(favorite_id) REFERENCES favorites(id)
                )
                """)
                
                conn.commit()
                print("æ•°æ®åº“åˆ›å»ºæˆåŠŸ")
                self.db_exists = True
                self.first_run = True  # æ ‡è®°ä¸ºé¦–æ¬¡è¿è¡Œ
            except Exception as e:
                print(f"åˆ›å»ºæ•°æ®åº“å¤±è´¥: {str(e)}")
            finally:
                if conn:
                    conn.close()
            return
        
        # å·²æœ‰æ•°æ®åº“æ—¶çš„å‡çº§é€»è¾‘
        try:
            conn = sqlite3.connect(DB_FILE)
            c = conn.cursor()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰last_updatedåˆ—
            c.execute("PRAGMA table_info(favorites)")
            columns = [col[1] for col in c.fetchall()]
            if "last_updated" not in columns:
                print("æ£€æµ‹åˆ°æ—§ç‰ˆæ•°æ®åº“ï¼Œæ­£åœ¨å‡çº§...")
                c.execute("ALTER TABLE favorites ADD COLUMN last_updated TEXT")
                current_time = datetime.now().isoformat()
                c.execute("UPDATE favorites SET last_updated=?", (current_time,))
                print("æ•°æ®åº“å‡çº§å®Œæˆ")
            
            conn.commit()
        except Exception as e:
            print(f"æ•°æ®åº“å‡çº§å¤±è´¥: {str(e)}")
        finally:
            if conn:
                conn.close()

    async def save_to_db(self, data: List[Dict]) -> bool:
        """ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“"""
        # ç¡®ä¿æ•°æ®åº“å­˜åœ¨ä¸”ç»“æ„æ­£ç¡®
        self.upgrade_database()
        
        conn = None
        try:
            conn = sqlite3.connect(DB_FILE)
            c = conn.cursor()
            
            # åœ¨ä¿å­˜æ‰€æœ‰æ•°æ®å‰è·å–å½“å‰æ—¶é—´
            current_time = datetime.now().isoformat()
            self.current_update_time = current_time
            
            total_items = 0
            
            for folder in data:
                # æ£€æŸ¥æ”¶è—å¤¹æ˜¯å¦å­˜åœ¨
                c.execute("SELECT 1 FROM favorites WHERE id=?", (folder["id"],))
                exists = c.fetchone()
                
                if exists:
                    # æ›´æ–°æ”¶è—å¤¹ä¿¡æ¯
                    c.execute(
                        "UPDATE favorites SET title=?, count=?, last_updated=? WHERE id=?",
                        (folder["title"], folder["media_count"], current_time, folder["id"])
                    )
                else:
                    # æ’å…¥æ–°æ”¶è—å¤¹
                    c.execute(
                        "INSERT INTO favorites (id, title, media_id, count, last_updated) VALUES (?, ?, ?, ?, ?)",
                        (folder["id"], folder["title"], folder["id"], folder["media_count"], current_time)
                    )
                
                # åˆ é™¤æ—§æ¡ç›®
                c.execute("DELETE FROM favorite_items WHERE favorite_id=?", (folder["id"],))
                
                for item in folder.get("items", []):
                    total_items += 1
                    owner = item.get("upper", {}).get("name", "æœªçŸ¥ä½œè€…") if "upper" in item else "æœªçŸ¥ä½œè€…"
                    bvid = item.get("bvid", "")
                    
                    # ä½¿ç”¨BVIDä½œä¸ºå”¯ä¸€æ ‡è¯†ç¬¦
                    item_id = f"{folder['id']}_{bvid}"
                    
                    # æ’å…¥æˆ–å¿½ç•¥é‡å¤é¡¹
                    c.execute(
                        "INSERT OR IGNORE INTO favorite_items (id, favorite_id, title, bvid, owner_name) VALUES (?, ?, ?, ?, ?)",
                        (item_id, folder["id"], item["title"], bvid, owner)
                    )
            
            conn.commit()
            print(f"æˆåŠŸä¿å­˜ {len(data)} ä¸ªæ”¶è—å¤¹ï¼Œå…±{total_items}ä¸ªé¡¹ç›®åˆ°æ•°æ®åº“")
            
            # æ›´æ–°æœ€åæ›´æ–°æ—¶é—´
            self.last_updated = datetime.fromisoformat(current_time)
            
            return True
        except sqlite3.IntegrityError as e:
            print(f"æ•°æ®åº“ä¿å­˜å¤±è´¥ (å”¯ä¸€çº¦æŸ): {str(e)}")
            return False
        except Exception as e:
            print(f"ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {str(e)}")
            return False
        finally:
            if conn:
                conn.close()

    def print_tree(self, data: List[Dict]):
        for folder in data:
            print(f"\nğŸ“ {folder['title']} ({folder['media_count']}é¡¹)")
            
            items = folder.get("items", [])
            for i, item in enumerate(items[:20]):
                prefix = "  â”œâ”€" if i < len(items)-1 else "  â””â”€"
                bvid = item.get("bvid", "æœªçŸ¥BVå·")
                owner = item.get("upper", {}).get("name", "æœªçŸ¥ä½œè€…") if "upper" in item else "æœªçŸ¥ä½œè€…"
                print(f"{prefix} {item['title']} {bvid} by {owner}")
            
            if len(items) > 20:
                print(f"  â””â”€ ...è¿˜æœ‰{len(items)-20}é¡¹æœªæ˜¾ç¤º")
            elif folder['media_count'] > len(items):
                print(f"  â””â”€ è·å–ä¸å®Œæ•´: åº”æœ‰{folder['media_count']}é¡¹ï¼Œå®é™…è·å–{len(items)}é¡¹")

    def get_favorite_videos(self, favorite_id: int) -> Tuple[str, List[Tuple[str, str]]]:
        try:
            conn = sqlite3.connect(DB_FILE)
            c = conn.cursor()
            
            c.execute("SELECT title FROM favorites WHERE id=?", (favorite_id,))
            row = c.fetchone()
            folder_title = row[0] if row else f"æ”¶è—å¤¹_{favorite_id}"
            
            c.execute("SELECT title, bvid FROM favorite_items WHERE favorite_id=?", (favorite_id,))
            videos = c.fetchall()
            return folder_title, videos
        except Exception as e:
            print(f"ä»æ•°æ®åº“è·å–æ”¶è—å¤¹è§†é¢‘å¤±è´¥: {str(e)}")
            return f"æ”¶è—å¤¹_{favorite_id}", []
        finally:
            if conn:
                conn.close()

    async def get_video_info(self, session: httpx.AsyncClient, bvid: str) -> Optional[Dict]:
        try:
            resp = await session.get(
                "https://api.bilibili.com/x/web-interface/view",
                params={"bvid": bvid},
                timeout=15.0
            )
            resp.raise_for_status()
            data = resp.json()
            if data.get("code") != 0:
                print(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {data.get('message')}")
                return None
            return data["data"]
        except Exception as e:
            print(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {str(e)}")
            return None

    async def get_video_url(self, session: httpx.AsyncClient, bvid: str, cid: int, quality: int = 80) -> Optional[Dict]:
        if not self.is_member and quality > NON_MEMBER_MAX_QUALITY:
            quality = NON_MEMBER_MAX_QUALITY
        
        # å¯¹äº360På’Œæœ€ä½æ¸…æ™°åº¦ï¼Œä¸ä½¿ç”¨DASHæ ¼å¼
        use_dash = quality not in [16, 6]  # 16=360P, 6=æœ€ä½
        
        # æ˜¾ç¤ºä½¿ç”¨çš„æ ¼å¼
        format_type = "DASH" if use_dash else "FLV"
        
        # è·å–æ¸…æ™°åº¦æè¿°
        quality_desc = QUALITY_CODE_TO_DESC.get(quality, f"{quality} (æœªçŸ¥)")
        
        print(f"æ¸…æ™°åº¦: {quality_desc} ({format_type}æ ¼å¼)")
        
        try:
            params = {
                "bvid": bvid,
                "cid": cid,
                "qn": quality,
                "fnval": 4048 if use_dash else 0,  # ä½¿ç”¨DASHæ ¼å¼
                "fourk": 1,
                "platform": "pc"
            }
            
            resp = await session.get(
                "https://api.bilibili.com/x/player/playurl",
                params=params,
                timeout=15.0
            )
            resp.raise_for_status()
            data = resp.json()
            
            if data.get("code") != 0:
                # å›é€€åˆ°éDASHæ ¼å¼
                params["fnval"] = 0
                resp = await session.get(
                    "https://api.bilibili.com/x/player/playurl",
                    params=params,
                    timeout=15.0
                )
                resp.raise_for_status()
                data = resp.json()
                if data.get("code") != 0:
                    return None
                
                return {
                    "video_url": data["data"]["durl"][0]["url"],
                    "audio_url": None,  # éDASHæ ¼å¼åŒ…å«éŸ³é¢‘
                    "format": "flv"
                }
            
            dash_data = data["data"].get("dash")
            if dash_data and use_dash:
                # è·å–è§†é¢‘æµ
                video_streams = dash_data.get("video", [])
                selected_video = None
                for stream in video_streams:
                    if stream.get("id") == quality:
                        selected_video = stream
                        break
                if not selected_video and video_streams:
                    # å¦‚æœæ²¡æœ‰åŒ¹é…çš„qualityï¼Œé€‰æ‹©æœ€é«˜è´¨é‡çš„è§†é¢‘æµ
                    video_streams.sort(key=lambda x: x.get("id", 0), reverse=True)
                    selected_video = video_streams[0]
                
                # è·å–éŸ³é¢‘æµ
                audio_streams = dash_data.get("audio", [])
                selected_audio = None
                if audio_streams:
                    # é€‰æ‹©æœ€é«˜è´¨é‡çš„éŸ³é¢‘æµ
                    audio_streams.sort(key=lambda x: x.get("bandwidth", 0), reverse=True)
                    selected_audio = audio_streams[0]
                
                if selected_video and selected_audio:
                    return {
                        "video_url": selected_video["baseUrl"],
                        "audio_url": selected_audio["baseUrl"],
                        "format": "dash"
                    }
            
            # éDASHæ ¼å¼æˆ–è·å–å¤±è´¥
            return {
                "video_url": data["data"]["durl"][0]["url"],
                "audio_url": None,
                "format": "flv"
            }
        except Exception as e:
            print(f"è·å–è§†é¢‘URLå¤±è´¥: {str(e)}")
            return None

    async def download_file(self, url: str, file_path: str, title: str, file_type: str, headers: Dict) -> bool:
        """å¼‚æ­¥ä¸‹è½½æ–‡ä»¶"""
        try:
            # éŸ³é¢‘ä¸‹è½½æ¢è¡Œæ˜¾ç¤º
            if file_type == "éŸ³é¢‘":
                print(f"\nå¼€å§‹ä¸‹è½½{file_type}: {title}")
            else:
                print(f"\nå¼€å§‹ä¸‹è½½{file_type}: {title}")
    
            async with httpx.AsyncClient(headers=headers, timeout=60.0) as client:
                async with client.stream("GET", url, follow_redirects=True) as response:
                    response.raise_for_status()
                    total_size = int(response.headers.get("Content-Length", 0))
            
                    # ç¡®ä¿æ–‡ä»¶å¤§å°æœ‰æ•ˆ
                    if total_size <= 0:
                        # å°è¯•ä»å†…å®¹ä¸­è·å–æ–‡ä»¶å¤§å°
                        if "Content-Range" in response.headers:
                            try:
                                total_size = int(response.headers["Content-Range"].split("/")[-1])
                            except:
                                # å¦‚æœæ— æ³•ç¡®å®šæ–‡ä»¶å¤§å°ï¼Œä½¿ç”¨é»˜è®¤å€¼
                                total_size = 1024 * 1024  # 1MB
                        else:
                            # å¦‚æœæ— æ³•ç¡®å®šæ–‡ä»¶å¤§å°ï¼Œä½¿ç”¨é»˜è®¤å€¼
                            total_size = 1024 * 1024  # 1MB
            
                    # ä½¿ç”¨tqdmæ ‡å‡†è¿›åº¦æ¡
                    pbar = tqdm(
                        total=total_size,
                        desc=f"{file_type}ä¸‹è½½: {title[:30]}",  # é™åˆ¶æ ‡é¢˜é•¿åº¦
                        unit="B",
                        unit_scale=True,
                        unit_divisor=1024,
                        miniters=1,
                        leave=True,  # å®Œæˆåä¸ä¿ç•™æ˜¾ç¤º
                        mininterval=0.1  # æœ€å°æ›´æ–°é—´éš”
                    )
            
                    try:
                        # ç¡®ä¿è¿›åº¦æ¡å·²åˆå§‹åŒ–
                        pbar.update(0)
                    
                        # ä¸‹è½½æ–‡ä»¶
                        downloaded_size = 0
                        with open(file_path, "wb") as f:
                            async for chunk in response.aiter_bytes(chunk_size=8192):
                                if interrupted:
                                    return False
                                f.write(chunk)
                                chunk_size = len(chunk)
                                pbar.update(chunk_size)
                                downloaded_size += chunk_size
                    
                        # ç¡®ä¿è¿›åº¦æ¡å®Œæˆ
                        if downloaded_size < total_size:
                            pbar.update(total_size - downloaded_size)
                    
                        return True
                    finally:
                        # æ˜¾å¼å…³é—­è¿›åº¦æ¡
                        pbar.close()
            
        except Exception as e:
            print(f"ä¸‹è½½{file_type}å¤±è´¥: {title} - {str(e)}")
            # åˆ é™¤å¯èƒ½ä¸å®Œæ•´çš„æ–‡ä»¶
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                except:
                    pass
            return False

    async def download_single_video(self, session: httpx.AsyncClient, bvid: str, title: str, output_path: str, quality: int, overwrite: bool = False) -> bool:
        global interrupted
        
        try:
            safe_title = sanitize_filename(title)
            # ç¼©çŸ­æ–‡ä»¶åé˜²æ­¢è·¯å¾„è¿‡é•¿
            safe_title = shorten_filename(safe_title)
            file_path = os.path.join(output_path, f"{safe_title}_{bvid}.mp4")
            
            if overwrite and os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    print(f"å·²åˆ é™¤æ—§æ–‡ä»¶: {title} ({bvid})")
                except Exception as e:
                    print(f"åˆ é™¤æ—§æ–‡ä»¶å¤±è´¥: {title} ({bvid}) - {str(e)}")
                    return False
            
            video_info = await self.get_video_info(session, bvid)
            if not video_info:
                print(f"è·³è¿‡è§†é¢‘: {title} ({bvid}) - æ— æ³•è·å–è§†é¢‘ä¿¡æ¯")
                return False
            
            cid = video_info["cid"]
            media_info = await self.get_video_url(session, bvid, cid, quality)
            if not media_info:
                print(f"è·³è¿‡è§†é¢‘: {title} ({bvid}) - æ— æ³•è·å–ä¸‹è½½é“¾æ¥")
                return False
            
            os.makedirs(output_path, exist_ok=True)
            
            headers = {
                "User-Agent": HEADERS["User-Agent"],
                "Referer": "https://www.bilibili.com",
                "Cookie": "; ".join([f"{k}={v}" for k, v in session.cookies.items()])
            }
            
            # ä¸‹è½½è§†é¢‘æ–‡ä»¶
            video_url = media_info["video_url"]
            video_file = os.path.join(output_path, f"{safe_title}_{bvid}_video.tmp")
            
            # ä¸‹è½½è§†é¢‘
            video_success = await self.download_file(
                video_url, video_file, title, "è§†é¢‘", headers
            )
            
            if not video_success:
                return False
            
            # ä¸‹è½½éŸ³é¢‘æ–‡ä»¶ï¼ˆå¦‚æœæ˜¯DASHæ ¼å¼ï¼‰
            audio_file = None
            audio_success = True
            
            if media_info["audio_url"] and self.ffmpeg_available:
                audio_url = media_info["audio_url"]
                audio_file = os.path.join(output_path, f"{safe_title}_{bvid}_audio.tmp")
                
                # ä¸‹è½½éŸ³é¢‘
                audio_success = await self.download_file(
                    audio_url, audio_file, title, "éŸ³é¢‘", headers
                )
            
            # å¦‚æœéŸ³é¢‘ä¸‹è½½å¤±è´¥ï¼Œä½†è§†é¢‘ä¸‹è½½æˆåŠŸï¼Œå°è¯•åªä¿å­˜è§†é¢‘
            if not audio_success:
                if os.path.exists(video_file):
                    try:
                        os.rename(video_file, file_path)
                        print(f"éŸ³é¢‘ä¸‹è½½å¤±è´¥ï¼Œå·²ä¿å­˜è§†é¢‘æ–‡ä»¶: {title}")
                        return True
                    except Exception as e:
                        print(f"é‡å‘½åè§†é¢‘æ–‡ä»¶å¤±è´¥: {title} - {str(e)}")
                        return False
                return False
            
            # å¯¹äºDASHæ ¼å¼ä¸”æœ‰éŸ³é¢‘æ–‡ä»¶ï¼ŒåŠ å…¥åˆå¹¶é˜Ÿåˆ—
            if audio_file and os.path.exists(audio_file):
                # åŠ å…¥åˆå¹¶é˜Ÿåˆ—ï¼ˆåå°çº¿ç¨‹ä¼šå¤„ç†ï¼‰
                self.queue_merge_task(video_file, audio_file, file_path, title, bvid)
                return True
            else:
                # éDASHæ ¼å¼ï¼Œç›´æ¥é‡å‘½åè§†é¢‘æ–‡ä»¶
                if os.path.exists(video_file):
                    try:
                        os.rename(video_file, file_path)
                        print(f"ä¸‹è½½å®Œæˆ: {title} ({bvid})")
                        return True
                    except Exception as e:
                        print(f"é‡å‘½åè§†é¢‘æ–‡ä»¶å¤±è´¥: {title} - {str(e)}")
                        return False
                return False
        except Exception as e:
            print(f"ä¸‹è½½å¤±è´¥: {title} ({bvid}) - {str(e)}")
            return False

    async def download_favorite_videos(self, session: httpx.AsyncClient, favorite_id: int, output_dir: str, quality: str):
        global interrupted, overwrite_all, skip_existing
    
        folder_title, videos = self.get_favorite_videos(favorite_id)
        if not videos:
            print("è¯¥æ”¶è—å¤¹ä¸­æ²¡æœ‰è§†é¢‘")
            return
    
        output_path = os.path.join(output_dir, folder_title)
        os.makedirs(output_path, exist_ok=True)
    
        print(f"å¼€å§‹ä¸‹è½½æ”¶è—å¤¹: {folder_title} ({len(videos)}ä¸ªè§†é¢‘)")
        print(f"ä¸‹è½½è·¯å¾„: {output_path}")
        print(f"æ¸…æ™°åº¦: {quality}")
    
        # æ˜¾ç¤ºFFmpegçŠ¶æ€
        if self.ffmpeg_available:
            print(f"FFmpegå¯ç”¨ (ç‰ˆæœ¬: {self.ffmpeg_version})")
        else:
            print("FFmpegä¸å¯ç”¨ï¼ŒDASHæ ¼å¼è§†é¢‘å°†æ— æ³•åˆå¹¶éŸ³é¢‘")
    
        quality_code = QUALITY_MAP.get(quality, 80)
    
        overwrite_all = False
        skip_existing = False
    
        download_tasks = []
        skipped_count = 0
        overwritten_count = 0
        new_videos = 0
    
        # å…ˆå¤„ç†æ‰€æœ‰æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
        for title, bvid in videos:
            if interrupted:
                break
            
            safe_title = sanitize_filename(title)
            safe_title = shorten_filename(safe_title)
            file_path = os.path.join(output_path, f"{safe_title}_{bvid}.mp4")
            file_exists = os.path.exists(file_path)
        
            if file_exists and skip_existing:
                skipped_count += 1
                continue
            
            if file_exists and overwrite_all:
                download_tasks.append((bvid, title, True))
                overwritten_count += 1
                continue
            
            if file_exists and not overwrite_all and not skip_existing:
                print(f"\nè§†é¢‘å·²å­˜åœ¨: {title} ({bvid})")
                print("è¯·é€‰æ‹©æ“ä½œ: [s]è·³è¿‡, [o]è¦†ç›–, [a]è¦†ç›–æ‰€æœ‰, [sa]è·³è¿‡æ‰€æœ‰, [c]å–æ¶ˆ (é»˜è®¤s): ", end='', flush=True)
                choice = input().strip().lower()
                if not choice:
                    choice = "s"
            
                if choice == "s":
                    skipped_count += 1
                    print("è·³è¿‡ä¸‹è½½")
                    continue
                elif choice == "o":
                    download_tasks.append((bvid, title, True))
                    overwritten_count += 1
                elif choice == "a":
                    download_tasks.append((bvid, title, True))
                    overwrite_all = True
                    overwritten_count += 1
                elif choice == "sa":
                    skip_existing = True
                    skipped_count += 1
                    print("è·³è¿‡æ‰€æœ‰å·²å­˜åœ¨è§†é¢‘")
                    continue
                elif choice == "c":
                    interrupted = True
                    break
                else:
                    skipped_count += 1
                    print("æ— æ•ˆé€‰é¡¹ï¼Œè·³è¿‡ä¸‹è½½")
                    continue
        
            if not file_exists:
                download_tasks.append((bvid, title, False))
                new_videos += 1
        # æ˜¾ç¤ºå¤„ç†ç»“æœ
        print(f"\nä¸‹è½½ä»»åŠ¡ç»Ÿè®¡:")
        print(f" - è·³è¿‡: {skipped_count} ä¸ªå·²å­˜åœ¨è§†é¢‘")
        print(f" - è¦†ç›–: {overwritten_count} ä¸ªè§†é¢‘")
        print(f" - æ–°å¢: {new_videos} ä¸ªæ–°è§†é¢‘")
        print(f" - æ€»è®¡: {len(download_tasks)} ä¸ªè§†é¢‘éœ€è¦ä¸‹è½½")
    
        if not download_tasks:
            print("æ²¡æœ‰éœ€è¦ä¸‹è½½çš„è§†é¢‘")
            return
    
        # ç°åœ¨å¼€å§‹ä¸‹è½½
        results = []
        for i, (bvid, title, overwrite) in enumerate(download_tasks, 1):
            if interrupted:
                break
            
            print(f"\n[{i}/{len(download_tasks)}] å¼€å§‹å¤„ç†è§†é¢‘: {title} ({bvid})")
            result = await self.download_single_video(
                session, bvid, title, output_path, quality_code, overwrite
            )
            results.append(result)
    
        # ç­‰å¾…åˆå¹¶é˜Ÿåˆ—å®Œæˆ
        while self.merge_queue and not interrupted:
            queue_size = len(self.merge_queue)
            print(f"ç­‰å¾…åˆå¹¶é˜Ÿåˆ—å®Œæˆ: å‰©ä½™ {queue_size} ä¸ªä»»åŠ¡...")
            if queue_size > 0:
                print(f"ä¸‹ä¸€ä¸ªä»»åŠ¡: {self.merge_queue[0][3]} ({self.merge_queue[0][4]})")
            await asyncio.sleep(5)
    
        success_count = sum(1 for r in results if r)
        failed_count = len(results) - success_count
    
        if not interrupted:
            print(f"\næ”¶è—å¤¹ä¸‹è½½å®Œæˆ: {folder_title}")
            print(f" - æˆåŠŸ: {success_count} ä¸ªè§†é¢‘")
            if failed_count > 0:
                print(f" - å¤±è´¥: {failed_count} ä¸ªè§†é¢‘")
            if skipped_count > 0:
                print(f" - è·³è¿‡: {skipped_count} ä¸ªå·²å­˜åœ¨è§†é¢‘")
            if new_videos > 0:
                print(f" - æ–°å¢: {new_videos} ä¸ªæ–°è§†é¢‘")

    async def fetch_and_update_favorites(self, session: httpx.AsyncClient) -> bool:
        global interrupted
        
        self.upgrade_database()
        
        # æ£€æŸ¥æ•°æ®åº“æœ€åæ›´æ–°æ—¶é—´
        default_choice = "n"
        update_reason = ""
        
        # é¦–æ¬¡è¿è¡Œå¼ºåˆ¶æ›´æ–°
        if self.first_run:
            default_choice = "y"
            update_reason = " (é¦–æ¬¡è¿è¡Œéœ€è¦åŒæ­¥æ”¶è—å¤¹)"
            print(f"\né¦–æ¬¡è¿è¡Œï¼Œéœ€è¦åŒæ­¥æ”¶è—å¤¹...")
        
        # æˆ–è€…æ•°æ®åº“è¶…è¿‡24å°æ—¶æœªæ›´æ–°
        elif self.last_updated:
            time_diff = datetime.now() - self.last_updated
            if time_diff > timedelta(hours=24):
                default_choice = "y"
                update_reason = f" (æ•°æ®åº“å·²è¶…è¿‡24å°æ—¶æœªæ›´æ–°ï¼Œæœ€åæ›´æ–°äº {self.last_updated.strftime('%Y-%m-%d %H:%M')})"
        
        if self.db_exists and not self.first_run:
            print("\næ£€æµ‹åˆ°æœ¬åœ°æ•°æ®åº“å­˜åœ¨")
            
            update = input(f"æ˜¯å¦æ›´æ–°æ”¶è—å¤¹æ•°æ®? (y/n, é»˜è®¤{default_choice}{update_reason}): ").strip().lower() or default_choice
            
            if update == "y":
                print("ä»Bç«™APIè·å–æœ€æ–°æ”¶è—å¤¹æ•°æ®...")
            else:
                print("ä½¿ç”¨æœ¬åœ°æ•°æ®åº“æ•°æ®")
                return self.load_from_db()
        else:
            print("ä»Bç«™APIè·å–æ”¶è—å¤¹æ•°æ®...")
        
        favorites = await self.get_favorites(session)
        if not favorites:
            return False
        
        self.all_data = []
        for fav in favorites:
            if interrupted:
                break
                
            # éšæœºå»¶è¿Ÿé˜²æ­¢è¯·æ±‚è¿‡å¿«
            delay = random.uniform(0.1, 0.8)
            await asyncio.sleep(delay)
            
            print(f"\næ­£åœ¨è·å–æ”¶è—å¤¹: {fav['title']} (ID: {fav['id']}, åº”æœ‰ {fav['media_count']} é¡¹)")
            
            try:
                items = await self.get_favorite_detail(session, fav["id"], fav["media_count"])
                self.all_data.append({
                    "id": fav["id"],
                    "title": fav["title"],
                    "media_count": fav["media_count"],
                    "items": items
                })
            except Exception as e:
                print(f"  â””â”€ è·å–å¤±è´¥: {str(e)}")
        
        if not interrupted and self.all_data:
            success = await self.save_to_db(self.all_data)
            # é‡ç½®é¦–æ¬¡è¿è¡Œæ ‡å¿—
            self.first_run = False
            return success
        else:
            return False

    def load_from_db(self) -> bool:
        try:
            conn = sqlite3.connect(DB_FILE)
            c = conn.cursor()
            
            c.execute("SELECT id, title, media_id, count, last_updated FROM favorites")
            folders = c.fetchall()
            
            self.all_data = []
            for folder in folders:
                c.execute("SELECT title, bvid, owner_name FROM favorite_items WHERE favorite_id=?", (folder[0],))
                items_rows = c.fetchall()
                items = [
                    {
                        "title": row[0],
                        "bvid": row[1],
                        "upper": {"name": row[2]}
                    }
                    for row in items_rows
                ]
                
                self.all_data.append({
                    "id": folder[0],
                    "title": folder[1],
                    "media_id": folder[2],
                    "media_count": folder[3],
                    "last_updated": folder[4],
                    "items": items
                })
            
            print(f"æˆåŠŸåŠ è½½ {len(self.all_data)} ä¸ªæ”¶è—å¤¹")
            return True
        except Exception as e:
            print(f"æ•°æ®åº“åŠ è½½å¤±è´¥: {str(e)}")
            return False
        finally:
            if conn:
                conn.close()

    async def run(self):
        global interrupted
        
        print("="*50)
        print("Bç«™æ”¶è—å¤¹è§†é¢‘ä¸‹è½½å™¨")
        print("="*50)
        print("æ­£åœ¨åˆå§‹åŒ–...")
        
        # åˆå§‹åŒ–å¹¶æ£€æŸ¥æ˜¯å¦æˆåŠŸ
        try:
            init_result = await self.initialize()
            if not init_result:
                print("åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•")
                # æä¾›æ›´å¤šè°ƒè¯•ä¿¡æ¯
                if not self.token_data:
                    print("åŸå› ï¼šæœªè·å–åˆ°æœ‰æ•ˆçš„ç™»å½•ä¿¡æ¯")
                elif not self.cookies:
                    print("åŸå› ï¼šæœªæ­£ç¡®è®¾ç½®Cookies")
                return
        except Exception as e:
            print(f"åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            return
        
        # æ·»åŠ ä¸­æ–­æ£€æŸ¥
        if interrupted:
            print("åˆå§‹åŒ–åæ£€æµ‹åˆ°ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
            return
            
        async with httpx.AsyncClient(
            headers=HEADERS,
            cookies=self.cookies,
            timeout=60.0
        ) as session:
            # æ·»åŠ ä¸­æ–­æ£€æŸ¥
            if interrupted:
                print("åˆå§‹åŒ–åæ£€æµ‹åˆ°ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
                return
                
            success = await self.fetch_and_update_favorites(session)
            
            # æ·»åŠ ä¸­æ–­æ£€æŸ¥
            if interrupted:
                print("è·å–æ”¶è—å¤¹åæ£€æµ‹åˆ°ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
                return
                
            if success and self.all_data:
                print("\næ”¶è—å¤¹å†…å®¹:")
                self.print_tree(self.all_data)
                
                while not interrupted:
                    print("\nè¯·é€‰æ‹©æ“ä½œ: 1. ä¸‹è½½æ”¶è—å¤¹è§†é¢‘  2. é€€å‡º")
                    print("è¯·è¾“å…¥é€‰é¡¹ (é»˜è®¤1): ", end="")
                    
                    choice = input().strip()
                    if not choice:
                        choice = "1"
                    
                    if choice == "1":
                        print("\næ”¶è—å¤¹åˆ—è¡¨:")
                        for folder in self.all_data:
                            print(f"ID: {folder['id']} - {folder['title']} ({folder['media_count']}é¡¹)")
                        
                        print("\nè¯·è¾“å…¥è¦ä¸‹è½½çš„æ”¶è—å¤¹ID: ", end="")
                        fav_id = input().strip()
                        if not fav_id.isdigit():
                            print("è¾“å…¥é”™è¯¯ï¼Œè¯·é‡æ–°è¾“å…¥")
                            continue
                        fav_id = int(fav_id)
                        
                        found = False
                        for folder in self.all_data:
                            if folder['id'] == fav_id:
                                found = True
                                break
                        if not found:
                            print("æ”¶è—å¤¹IDä¸å­˜åœ¨")
                            continue
                        
                        # åˆ›å»ºæ¸…æ™°åº¦é€‰é¡¹åˆ—è¡¨
                        quality_options = list(QUALITY_MAP.keys())
                        
                        # æ˜¾ç¤ºå¸¦ç¼–å·çš„æ¸…æ™°åº¦é€‰é¡¹
                        print("\nå¯ç”¨æ¸…æ™°åº¦:")
                        for i, q in enumerate(quality_options, 1):
                            print(f"{i}. {q}")
                        
                        # è·å–ç”¨æˆ·é€‰æ‹©
                        default_quality_index = quality_options.index('1080P') + 1 if '1080P' in quality_options else 4
                        print(f"è¯·é€‰æ‹©æ¸…æ™°åº¦ (1-{len(quality_options)}, é»˜è®¤{default_quality_index}): ", end="")
                        quality_choice = input().strip()
                        
                        # å¤„ç†é»˜è®¤å€¼
                        if not quality_choice:
                            quality_choice = str(default_quality_index)
                        
                        # éªŒè¯å¹¶è·å–æ¸…æ™°åº¦
                        if quality_choice.isdigit():
                            choice_index = int(quality_choice) - 1
                            if 0 <= choice_index < len(quality_options):
                                quality = quality_options[choice_index]
                            else:
                                print(f"è¾“å…¥è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨é»˜è®¤{quality_options[default_quality_index-1]}")
                                quality = quality_options[default_quality_index-1]
                        else:
                            print(f"æ— æ•ˆè¾“å…¥ï¼Œä½¿ç”¨é»˜è®¤{quality_options[default_quality_index-1]}")
                            quality = quality_options[default_quality_index-1]
                        
                        # éä¼šå‘˜æ¸…æ™°åº¦è°ƒæ•´
                        if not self.is_member and QUALITY_MAP.get(quality, 0) > NON_MEMBER_MAX_QUALITY:
                            print(f"æ™®é€šè´¦å·æœ€é«˜æ”¯æŒ1080Pï¼Œå·²è‡ªåŠ¨è°ƒæ•´ä¸º1080P")
                            quality = "1080P"
                        
                        print("è¯·è¾“å…¥ä¸‹è½½è·¯å¾„ (é»˜è®¤./favourite_download): ", end="")
                        output_dir = input().strip() or "./favourite_download"
                        
                        # æ·»åŠ ä¸­æ–­æ£€æŸ¥
                        if interrupted:
                            print("å¼€å§‹ä¸‹è½½å‰æ£€æµ‹åˆ°ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
                            break
                        
                        await self.download_favorite_videos(session, fav_id, output_dir, quality)
                    elif choice == "2":
                        print("é€€å‡ºç¨‹åº")
                        break
                    else:
                        print("æ— æ•ˆé€‰é¡¹ï¼Œè¯·é‡æ–°è¾“å…¥")
            else:
                print("æœªèƒ½è·å–æ”¶è—å¤¹æ•°æ®")
    
        self.stop_merge_thread()

if __name__ == "__main__":
    downloader = None
    try:
        downloader = BiliFavDownloader()
        asyncio.run(downloader.run())
    except Exception as e:
        print(f"ç¨‹åºå‘ç”Ÿé”™è¯¯: {str(e)}")
    finally:
        if downloader and hasattr(downloader, 'stop_merge_thread'):
            downloader.stop_merge_thread()
